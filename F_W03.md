# 备考复习（Lecture/Tutorial） - Week 3

欢迎来到第三周的学习。上周我们关注于如何“评估”预测的好坏，本周将深入“模型”本身，理解那些生成预测的底层引擎。将从最基础的模型开始，逐步建立起对时间序列分析至关重要的核心概念，特别是“平稳性 (Stationarity)”。

## 1. 模型的基石：白噪声 (White Noise)

在探索复杂的时间序列模型之前，我们必须先理解构成它们的“原子”——那些纯粹的、不可预测的随机性。这个“原子”就是白噪声。

### 1.1. 什么是白噪声？ (What is a White Noise Process?)

想象一下，你每天记录蜜雪东城奶茶店的销售额。除了季节、促销等可解释的因素外，总会有一些无法解释的、纯粹随机的波动（比如今天某个顾客心情好突然多买了一杯）。这些完全随机、没有规律可循的部分，就是白噪声。

一个时间序列 `εt` 如果是白噪声过程，必须满足以下三个条件：
1.  **期望为零 (Zero Mean)**: `E(εt) = 0`。从长期来看，这些随机波动的均值为0，它们不会系统性地偏高或偏低。
2.  **方差恒定 (Constant Variance)**: `V(εt) = σ²`。无论是在周一还是周五，这些随机波动的剧烈程度（方差）是相同的。
3.  **序列不相关 (No Autocorrelation)**: `Cov(εt, εs) = 0`，对于所有 `t ≠ s`。今天随机多卖一杯奶茶的事件，与昨天或明天是否随机多卖一杯完全无关。这个协方差也被称为 **自协方差 (Autocovariance)**。

总结来说，白噪声序列是 **独立同分布 (independent and identically distributed, i.i.d.)** 的。它本身没有任何可供预测的模式，但它却是构建更复杂、更有用模型（如AR模型）的关键组成部分。

### 1.2. 白噪声的用途 (Application of White Noise)

白噪声本身对于预测“没有直接价值”，因为我们无法预测随机性。但它的核心用途是作为 **模型诊断工具**。当我们建立一个时间序列模型后，模型的残差（即真实值 - 预测值）应该是一个白噪声序列。如果残差不是白噪声，那就说明我们的模型没有完全捕捉到数据中的规律，还有可提升的空间。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 下列哪个选项 **不是** 白噪声过程的必要属性？
    A. 均值为0
    B. 方差必须为1
    C. 任意两个不同时间点的变量相互独立
    D. 方差不随时间改变

2.  (判断题) 某时间序列模型的残差序列，其均值为0.01，方差为0.5，且自相关图显示在所有非零滞后阶数上均不显著。可以认为这个模型已经很好地捕捉了原始数据的信息。

3.  (思考题) 蜜雪东城记录了每日的顾客投诉量。你认为这个序列会是白噪声序列吗？为什么？

4.  (单选题) 如果一个序列 `εt` 的方差 `V(εt) = t`，其中 `t` 代表天数（第1天，第2天...），这个序列违反了白噪声的哪个条件？
    A. 期望为零
    B. 序列不相关
    C. 方差恒定
    D. 没什么问题，它依然是白噪声

5.  (判断题) 白噪声过程是时间序列分析的最终目标，因为它的模式最简单。

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。白噪声要求方差恒定 (`σ²`)，但并没有要求方差必须等于1。`σ²` 可以是任何大于0的常数。

2.  **答案: 错误**。尽管残差的均值接近于0且序列不相关，但一个“好”的模型残差应该表现为白噪声。白噪声的核心条件之一是均值严格为0 (`E(εt) = 0`)。均值为0.01意味着模型的预测存在一个微小但系统性的偏置（总是稍微低估或高估），因此模型还有改进的余地。

3.  **答案: 不太可能**。顾客投诉量通常存在自相关性。例如，一个严重的产品质量问题可能会在接下来几天内持续引发投诉，直到问题被解决。这就意味着今天的投诉量和昨天的投诉量可能相关，违反了白噪声的“序列不相关”条件。

4.  **答案: C**。该序列的方差直接依赖于时间 `t`，每天的方差都不同（越来越大），这明确违反了“方差恒定”的条件。

5.  **答案: 错误**。白噪声本身是“不可预测”的，它不是我们希望原始数据呈现的模式。在模型构建中，我们希望 **模型的残差** 是白噪声，这证明我们的模型已经成功提取了所有可预测的规律。

---

## 2. 引入记忆：自回归模型 AR(1) (Autoregressive Model)

现实世界中的时间序列数据，如股票价格、气温、销售额等，显然不是白噪声。它们的特点是“今天”和“昨天”之间存在某种联系。AR模型就是用来捕捉这种“时间惯性”或“记忆”的。

### 2.1. AR(1) 模型的核心思想 (The Idea of AR(1))

AR(1) 是自回归模型最简单的形式，其全称为 **一阶自回归模型 (First-Order Autoregressive Model)**。它的逻辑非常直观：**当前值主要由其前一期的值决定，再加上一点随机扰动。**

其数学表达式为：
`Yt = φYt-1 + εt`

*   `Yt`: 时间序列在当前 (`t`) 时刻的取值。
*   `Yt-1`: 时间序列在上一期 (`t-1`) 的取值。
*   `φ` (phi): 自回归系数。这是模型的关键参数，它衡量了上一期的值对当前值的影响程度或“记忆的强度”。
*   `εt`: 白噪声项。代表了在 `t` 时刻发生的、无法被过去值所解释的随机“新息 (innovation)”或“冲击 (shock)”。

### 2.2. AR(1) 模型的延伸：加入常数项 (AR(1) with a Constant)

基础的 AR(1) 模型是在0附近波动的。但在现实中，很多时间序列（如销售额）的波动中心并非为0。为了描述这类数据，可以在模型中加入一个常数项 `c`。

模型表达式变为：
`Yt = c + φYt-1 + εt`

这个常数项 `c` 与系数 `φ` 共同决定了序列的长期均值水平。当序列是平稳的时候（我们稍后会详细讲解），其均值为 `E(Yt) = c / (1 - φ)`。

### 2.3. 举个例子：蜜雪东城的日销售额

假设蜜雪东城某款奶茶的日销售额 `Yt` 可以用一个 AR(1) 模型来描述：
`Yt = 50 + 0.7 * Yt-1 + εt`

*   `c = 50`: 这部分可以理解为基础销量，即使昨天销量为0，今天也保底能产生50杯的销售额相关因素。
*   `φ = 0.7`: 这表示今天销售额的70%可以由昨天的销售额来解释。如果昨天卖得好，这种势头会以70%的强度延续到今天。
*   `εt`: 代表今天发生的、与昨天销量无关的随机事件，如天气突变、门口修路等，导致的销量波动。

如果昨天的销量 `Yt-1` 是300杯，那么我们对今天销量的最佳点预测就是：
`E(Yt) = 50 + 0.7 * 300 = 50 + 210 = 260` 杯。
实际销量将是260杯加上一个随机的波动 `εt`。

这个模型的长期平均销售额为 `E(Y) = 50 / (1 - 0.7) = 50 / 0.3 ≈ 167` 杯。这意味着，无论单日销量如何波动，从长远来看，它总会倾向于回归到167杯的水平。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 在 AR(1) 模型 `Yt = 10 + 0.9 * Yt-1 + εt` 中，参数 `0.9` 代表什么？
    A. 序列的长期平均值
    B. 随机冲击的平均大小
    C. 上一期数值对当期数值影响的强度
    D. 序列的固定增长率

2.  (计算题) 假设某只股票的日收益率 `Rt` 服从 `Rt = -0.1 * Rt-1 + εt`。如果昨天的收益率 (`Rt-1`) 为 5%，那么今天收益率的期望值是多少？

3.  (思考题) 为什么我们称之为“自”回归 (Auto-Regressive) 模型？它与我们之前学习的简单线性回归有何异同？

4.  (单选题) 对于模型 `Yt = 100 - 0.5 * Yt-1 + εt`，该序列的长期均值是多少？
    A. 100
    B. 200
    C. 66.67
    D. 50

5.  (判断题) 在 AR(1) 模型中，如果 `φ = 0`，那么 `Yt` 序列就是一个白噪声序列。

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: C**。`φ` 系数（这里是0.9）直接衡量了 `Yt-1` 对 `Yt` 的线性依赖程度。值越接近1，说明“记忆”越强；值越接近0，说明依赖性越弱。

2.  **答案: -0.5%**。直接将 `Rt-1 = 5%` 代入公式：`E(Rt) = -0.1 * 5% = -0.5%`。这意味着，如果昨天有正收益，模型预测今天的收益会倾向于是负的（均值回归的一种表现）。

3.  **答案:**
    *   **“自”的含义**: "Auto" 在这里指“自身”。这个模型是用时间序列“过去的值”来预测“未来的值”，即变量对自身进行回归，因此称为“自回归”。
    *   **与简单线性回归的异同**:
        *   **相同点**: 数学形式上都是线性关系，`Y = a + bX + ε`。
        *   **不同点**: 在简单线性回归中，`X` 通常是另一个完全不同的解释变量（如用广告支出 `X` 预测销售额 `Y`）。而在自回归模型中，解释变量 `X` 就是被解释变量 `Y` 自己的滞后项（`Yt-1`）。

4.  **答案: C**。使用长期均值公式 `E(Y) = c / (1 - φ)`。这里 `c = 100`，`φ = -0.5`。所以，`E(Y) = 100 / (1 - (-0.5)) = 100 / 1.5 ≈ 66.67`。

5.  **答案: 正确**。如果 `φ = 0`，模型就变成了 `Yt = c + εt`（如果 `c=0`）或 `Yt = εt`。这意味着 `Yt` 的值只由一个常数和当期的随机冲击决定，与过去的值完全无关。如果 `c=0` 且 `εt` 是白噪声，那么 `Yt` 本身就是一个白噪声序列。如果 `c` 非0，它是一个均值为 `c` 的白噪声序列。

---

## 3. 边界情况：随机游走 (Random Walk)

当我们不断调整 AR(1) 模型中的 `φ` 参数时，会发现一个非常特殊且重要的临界点：`φ = 1`。此时，模型将发生质变，从一个有“回复力”的系统变成了一个没有“记忆锚点”的随机游走过程。

### 3.1. 随机游走模型的定义 (What is a Random Walk?)

当 AR(1) 模型中的 `φ = 1` 时，模型就变成了随机游走模型。

其数学表达式为：
`Yt = Yt-1 + εt`

这个公式的含义是：**今天的值 = 昨天的值 + 一个随机的步伐**。

这里的 `εt` (白噪声) 就是每一步的大小和方向。因为 `εt` 的期望为0，所以每一步可能是向上也可能是向下，但平均来看没有固定的方向。

### 3.2. 随机游走与 AR(1) 的本质区别 (The Crucial Difference)

*   **AR(1) (当 |φ| < 1)**: 具有 **均值回归 (Mean Reversion)** 的特性。无论序列因为随机冲击偏离其长期均值多远，模型内在的机制 (`φ` < 1) 会像一根“橡皮筋”一样，慢慢地把它拉回到均值附近。昨天的“冲击” `εt-1` 对今天 `Yt` 的影响是 `φ*εt-1`，对后天 `Yt+1` 的影响是 `φ²*εt-1`，影响会随时间指数级衰减。模型会“忘记”遥远的过去。
*   **随机游走**: **没有均值回归** 的特性。它没有长期均值这个“锚点”。每一步都是在前一步的基础上叠加一个新的随机量。这意味着，过去的每一次随机冲击 `ε` 都会被 **永久地记住**，并累积在当前值 `Yt` 中。可以通过递归代换看到这一点：
    `Yt = Yt-1 + εt = (Yt-2 + εt-1) + εt = ... = Y0 + ε1 + ε2 + ... + εt`
    `Yt` 的值是初始值 `Y0` 和历史上所有冲击的总和。它没有“橡皮筋”，一旦走远了，就再也没有力量把它拉回来。

### 3.3. 随机游走的变体：带漂移的随机游走 (Random Walk with Drift)

如果我们给随机游走模型加上一个常数项 `c`，它就变成了带漂移的随机游走。

数学表达式为：
`Yt = c + Yt-1 + εt`

这里的常数 `c` 扮演了 **漂移项 (drift)** 的角色。它意味着，除了随机的上下波动外，序列在每个时间点还有一个固定的、确定性的增长（或减少）。这就像一个人在随机左右摇摆的同时，还在稳步地向前走。这个模型常常被用来描述那些有明显长期趋势的金融资产价格。

### 3.4. 举个例子：股价与累计利润

*   **股价 (对数价格)**: 很多金融理论认为，股票的对数价格近似服从随机游走。今天的股价是在昨天股价的基础上，增加了一个随机的收益率。我们无法预测股价会“回归”到某个特定值，我们能做的最好预测就是“明天的股价约等于今天的股价”。
*   **蜜雪东城的累计利润**: 假设蜜雪东城每天的净利润是一个均值为 `c = ￥500` 的白噪声序列（即 `πt = 500 + εt`）。那么，公司的累计利润 `P_total(t)` 就是一个带漂移的随机游走过程。
    `P_total(t) = P_total(t-1) + πt = 500 + P_total(t-1) + εt`
    这个累计利润序列会有一个明显的上升趋势（每天平均增长500元），同时伴随着每日利润的随机波动。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 随机游走模型 `Yt = Yt-1 + εt` 的最佳“一步向前”预测 `E(Yt+1 | Yt)` 是什么？
    A. 0
    B. Yt
    C. Yt-1
    D. 无法确定

2.  (判断题) 一个 AR(1) 模型 `Yt = 0.99 * Yt-1 + εt` 和一个随机游走模型在短期内的表现会非常相似，但在长期则会截然不同。

3.  (单选题) 对于带漂移的随机游走 `Yt = -2 + Yt-1 + εt`，可以预期该序列的长期行为是？
    A. 围绕 -2 波动
    B. 保持在0附近
    C. 呈现稳步下降的趋势
    D. 呈现稳步上升的趋势

4.  (思考题) 为什么说随机游走过程的方差是随时间变化的（time-dependent）？请从 `Yt = Y0 + Σ εi` 的角度解释。

5.  (单选题) 下列哪个现象最适合用随机游走模型来描述？
    A. 每日最高气温的变化
    B. 某公司股票的每日收盘价
    C. 一年内某商品的月度销量
    D. 学生每次模拟考试的成绩

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。根据模型 `Yt+1 = Yt + εt+1`，在 `t` 时刻 `Yt` 是已知的。我们求期望 `E(Yt+1 | Yt) = E(Yt + εt+1 | Yt) = Yt + E(εt+1) = Yt + 0 = Yt`。这就是著名的“朴素预测 (naive forecast)”，即最好的预测就是当前值。

2.  **答案: 正确**。当 `φ = 0.99` 时，它非常接近1。在短期内，序列的行为会像随机游走一样，持续偏离均值。但由于 `φ` 仍然小于1，从极长的尺度来看，它最终还是会回归均值。而随机游走则永远不会回归。这种区别在短期内很难察觉。

3.  **答案: C**。漂移项 `c = -2` 是负数，这意味着在每个时间步，序列的期望值都会减少2。因此，尽管有随机波动，但整体趋势是稳步下降的。

4.  **答案**:
    `Yt` 可以表示为从0到 `t` 的所有随机冲击 `ε` 的累加和，即 `Yt = Y0 + ε1 + ε2 + ... + εt`。
    我们来计算它的方差 `Var(Yt)` (假设 `Y0` 是一个常数, `Var(Y0)=0`):
    `Var(Yt) = Var(ε1 + ε2 + ... + εt)`
    因为白噪声的各个 `ε` 之间是相互独立的，所以和的方差等于方差的和：
    `Var(Yt) = Var(ε1) + Var(ε2) + ... + Var(εt)`
    又因为白噪声的方差恒为 `σ²`：
    `Var(Yt) = σ² + σ² + ... + σ²` (共 `t` 个)
    `Var(Yt) = t * σ²`
    因此，`Yt` 的方差直接依赖于时间 `t`，随着时间的推移，方差线性增长，序列的不确定性越来越大。

5.  **答案: B**。股票价格通常被认为是随机游走的，因为它反映了所有当前可知的信息，未来的价格变动主要由不可预测的“新消息”（即 `εt`）驱动。而气温、销量通常有明显的均值回归和季节性，考试成绩也可能因为学习而趋于稳定或提高，不符合随机游走的特性。

---

## 4. 描述模型的“性格”：平稳性与遍历性 (Stationarity and Ergodicity)

平稳性是衡量时间序列“稳定性”的一组统计特性。一个平稳的序列，其内在的统计规律不会随时间的推移而改变。这对于建模和预测至关重要，因为我们是在用过去的规律来预测未来，如果规律本身一直在变，那预测就无从谈起了。

### 4.1. 理解平稳性的核心：无条件分布 (Unconditional Distribution)

要理解平稳性，我们必须区分 **条件分布** 和 **无条件分布**。
*   **条件分布 (Conditional Distribution)**: 是指“在已知过去所有信息的条件下”，我们对下一个时间点数值的分布预测。例如 `P(Yt | Yt-1, Yt-2, ...)`。这对于“预测”至关重要。
*   **无条件分布 (Unconditional Distribution)**: 是指“抛开任何具体的时间点和历史信息”，从一个“上帝视角”来看，这个时间序列过程中任意一个点 `Yt` 的可能性分布。可以想象存在无数个平行宇宙，每个宇宙里都有一个该模型的实现，我们在 `t` 时刻把所有宇宙里的 `Yt` 值收集起来，得到的分布就是无条件分布 `P(Yt)`。平稳性就是关于这个无日志分布的性质。

平稳性分为两种：弱平稳和强平稳。

### 4.2. 弱平稳性 (Weak Stationarity)

弱平稳性是我们在实践中最常用到的概念。它不要求整个分布一成不变，只要求与均值和方差相关的“低阶矩”保持稳定。一个时间序列是弱平稳的，必须满足以下三个条件：

1.  **均值恒定 (Constant Mean)**: `E(Yt) = μ`
    *   **解读**: 序列波动的中心（期望值）不随时间改变。无论是序列的早期、中期还是晚期，其长期平均水平都是同一个值 `μ`。
    *   **反例**: 一个带有向上趋势的随机游走（`Yt = c + Yt-1 + εt`, c>0），其期望值 `E(Yt) = Y0 + c*t` 随时间 `t` 增长，因此它不是均值平稳的。

2.  **方差恒定 (Constant Variance)**: `V(Yt) = σ²`
    *   **解读**: 序列的波动剧烈程度（方差）不随时间改变。它不会在某些时期表现得非常平缓，而在另一些时期又变得异常动荡。
    *   **反例**: 标准的随机游走 `Yt = Yt-1 + εt`，我们之前证明了其方差 `V(Yt) = t * σ²`，方差随时间线性增长，因此它不是方差平稳的。

3.  **自协方差仅依赖于时间间隔 (Autocovariance depends only on lag)**: `Cov(Yt, Yt-τ) = γ(τ)`
    *   **解读**: 这是最关键的一点。序列中任意两个点之间的关联程度，只取决于它们相距多远（时间间隔 `τ`），而与它们在时间轴上的具体位置 (`t`) 无关。
    *   **举例**: `Cov(Y100, Y98)`（间隔`τ=2`）应该等于 `Cov(Y5, Y3)`（间隔`τ=2`）。今天和前天的关系，与下周二和上周日的关系，在统计上是一样的。序列的“内部记忆结构”是恒定的。

**总结：一个弱平稳序列，其均值、方差和自相关结构都是“时不变”的 (time-invariant)。**

### 4.3. 强平稳性 (Strong Stationarity)

强平稳性是一个更严格的数学定义。它要求序列的 **整个联合概率分布** 都不因时间的平移而改变。也就是说，对于任意的时间点 `t` 和任意的时间间隔 `τ1, τ2, ..., τk`，联合分布 `F(Yt, Yt+τ1, ..., Yt+τk)` 都是相同的。

这意味着不仅均值、方差、自协方差不变，所有的高阶矩（如偏度、峰度等）也都必须保持不变。

**关系**: 强平稳性一定蕴含弱平稳性。反之不成立。但有一个重要的特例：如果一个时间序列服从 **正态分布（高斯过程）**，那么弱平稳就等价于强平稳。因为正态分布完全由其均值、方差和协方差决定。

### 4.4. 遍历性 (Ergodicity)

这是一个更深层次的统计概念，但对我们理解为什么能用一段数据来建模至关重要。
*   **挑战**: 理论上，要计算一个序列的无条件均值 `μ`，需要观察所有“平行宇宙”中的 `Yt`。但在现实中，我们只有一个样本实现（比如，从1950年到今天的标普500指数）。
*   **遍历性的作用**: 它是一个美好的属性，它保证了 **时间平均等于集合平均**。也就是说，只要我们的单个样本序列足够长，我们通过计算这段序列的样本均值，就能得到对真实无条件均值 `μ` 的一个良好估计。

**简单来说，遍历性是我们能够用过去推断总体的统计学基石。** 对于我们课程中讨论的平稳AR模型，通常都满足遍历性。

### 4.5. 模型归类

现在可以为之前学习的模型贴上“平稳”或“非平稳”的标签了：
*   **白噪声**: **平稳的**。它满足平稳性的所有定义。
*   **AR(1) 模型 (当 |φ| < 1)**: **平稳的**。它会围绕一个固定均值波动，方差和自相关结构也都是恒定的。
*   **随机游走 (当 φ = 1)**: **非平稳的 (Non-stationary)**。它的方差随时间增长，不满足平稳性条件。这种非平稳序列也被称为含有 **单位根 (Unit Root)**。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 某时间序列的波动性在金融危机期间显著增大，而在其他时间段则相对稳定。这主要违反了弱平稳性的哪个条件？
    A. 均值恒定
    B. 方差恒定
    C. 自协方差仅依赖于时间间隔
    D. 遍历性

2.  (判断题) 只要一个时间序列的均值和方差不随时间改变，它就是弱平稳的。

3.  (单选题) 以下哪个模型是典型的非平稳时间序列模型？
    A. `Yt = 0.5 * Yt-1 + εt`
    B. `Yt = 2 + εt` (εt 为白噪声)
    C. `Yt = Yt-1 + εt`
    D. `εt` (εt 为白噪声)

4.  (思考题) 蜜雪东城每个季度的奶茶销量数据显示，夏季销量总是远高于冬季。如果我们观察原始的月度销量数据，它是否可能是平稳的？为什么？

5.  (单选题) “遍历性”这个属性为什么对时间序列分析师如此重要？
    A. 它保证了模型预测总是准确的。
    B. 它允许我们用单次观测到的、足够长的时间序列样本来估计整个随机过程的真实统计特性（如均值）。
    C. 它确保了时间序列一定是正态分布的。
    D. 它说明了序列中没有自相关。

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。描述“波动性”的统计量是方差。如果波动性在不同时期有显著差异，意味着方差不是一个常数，这直接违反了“方差恒定”的条件。

2.  **答案: 错误**。弱平稳性有三个条件。除了均值和方差恒定外，还必须满足第三个条件：自协方差结构不随时间改变。一个序列可能均值方差都稳定，但其内部的“记忆模式”可能在变化，这样的序列也不是平稳的。

3.  **答案: C**。`Yt = Yt-1 + εt` 是随机游走模型的定义，它是非平稳的经典例子，因为它含有单位根 (`φ=1`)。选项A是平稳的AR(1)模型。选项B和D都是平稳的（白噪声或带常数的白噪声）。

4.  **答案: 不太可能平稳**。这种明显的 **季节性 (Seasonality)** 模式违反了平稳性。具体来说，它违反了“均值恒定”的条件。如果我们看一月份的平均销量，它会系统性地低于七月份的平均销量。也就是说，序列的期望值 `E(Yt)` 依赖于 `t` 所在的季节，而不是一个固定的常数 `μ`。

5.  **答案: B**。遍历性是理论与实践之间的桥梁。它赋予了我们使用手头唯一的、有限的历史数据去推断背后那个随机过程的无限、抽象的统计特性的合法性。没有遍历性假设，我们从样本中计算出的均值或方差将毫无意义。


---

## 5. 深入模型内在：AR(1) 的平稳性证明与矩估计 (Proving Stationarity & Moments of AR(1))

要剖析 AR(1) 模型的内在属性，一个极其强大的工具是 **移动平均表示 (Moving Average Representation, MA)**。通过这个工具，可以将一个依赖于自身过去值的 AR 模型，改写成一个只依赖于过去所有随机冲击 `ε` 的形式。

### 5.1. AR(1) 的移动平均 (MA(∞)) 表示

我们从 AR(1) 模型 `Yt = φYt-1 + εt` 开始，进行反复的 **递归代换 (Recursive Substitution)**：

1.  **第一次代换**: 将 `Yt-1 = φYt-2 + εt-1` 代入原式：
    `Yt = φ(φYt-2 + εt-1) + εt = φ²Yt-2 + φεt-1 + εt`

2.  **第二次代换**: 将 `Yt-2 = φYt-3 + εt-2` 代入上式：
    `Yt = φ²(φYt-3 + εt-2) + φεt-1 + εt = φ³Yt-3 + φ²εt-2 + φεt-1 + εt`

3.  **推广到 J 步**: 持续这个过程 `J` 次，可以得到一个通用形式：
    `Yt = φ^J * Yt-J + Σ(j=0 to J-1) φ^j * εt-j`
    这个式子告诉我们，`Yt` 的值由两部分构成：一部分是 `J` 期前的值 `Yt-J` 的影响，另一部分是最近 `J` 期所有随机冲击的加权和。

4.  **关键的收敛条件**: 现在我们来思考，当 `J → ∞` 时会发生什么？
    *   **如果 |φ| < 1**: 那么 `φ^J` 这一项会随着 `J` 的增大而趋向于 0 (`lim(J→∞) φ^J = 0`)。这意味着，遥远过去 (`t-J`) 的某个具体值 `Yt-J` 对当前值 `Yt` 的影响会完全消失。模型会“遗忘”掉无限遥远的过去。
    *   **如果 |φ| ≥ 1**: 那么 `φ^J` 不会趋向于 0。特别是当 `φ=1`（随机游走）时，`φ^J=1`，`Yt-J` 的影响永远不会消失。模型会“永久记住”遥远的过去。

正是这个收敛条件，构成了平稳与非平稳的根本分界线。对于平稳的 AR(1) 模型 (|φ|<1)，当 `J→∞` 时，`φ^J * Yt-J` 消失，我们得到其 **无穷阶移动平均 (MA(∞)) 表示**:

`Yt = Σ(j=0 to ∞) φ^j * εt-j = εt + φεt-1 + φ²εt-2 + ...`

这个表达式的意义非常深刻：一个平稳的 AR(1) 过程，可以被看作是 **所有过去随机冲击的加权和**。权重 `φ^j` 随着时间的久远呈指数级衰减，意味着最近的冲击影响最大，而遥远的冲击影响微乎其微。

### 5.2. 计算无条件矩 (Calculating Unconditional Moments)

有了 MA(∞) 表示，我们就可以轻松地计算 AR(1) 模型的无条件均值、方差和自协方差，并以此来证明其弱平稳性。

**1. 无条件均值 `E(Yt)`:**
我们对 MA(∞) 表示求期望：
`E(Yt) = E(Σ φ^j * εt-j) = Σ φ^j * E(εt-j)`
由于 `ε` 是白噪声，`E(εt-j) = 0` 对于所有的 `j`。
因此，`E(Yt) = Σ φ^j * 0 = 0`。
*   **结论**: 对于 `Yt = φYt-1 + εt` 模型，其无条件均值为0，是一个与时间 `t` 无关的常数。
*   **对于带常数项的模型 `Yt = c + φYt-1 + εt`**, 通过类似推导可得 `E(Yt) = c / (1-φ)`，同样是一个常数。这满足了弱平稳性的第一个条件。

**2. 无条件方差 `V(Yt)`:**
我们对 MA(∞) 表示求方差：
`V(Yt) = V(Σ φ^j * εt-j)`
由于 `εt-j` 之间相互独立（白噪声的性质），因此和的方差等于各项方差的和：
`V(Yt) = Σ V(φ^j * εt-j) = Σ (φ^j)² * V(εt-j)`
由于 `ε` 的方差恒为 `σ²`，即 `V(εt-j) = σ²`：
`V(Yt) = Σ (φ²)^j * σ² = σ² * Σ(j=0 to ∞) (φ²)^j`
这是一个公比为 `φ²` 的无穷等比数列求和。因为 `|φ|<1`，所以 `|φ²|<1`，该级数收敛。
根据几何级数求和公式 `Σ x^j = 1 / (1-x)`，我们得到：
`V(Yt) = σ² * (1 / (1 - φ²))`
*   **结论**: 只要 `|φ|<1`，`V(Yt)` 是一个有限的、与时间 `t` 无关的正常数。这满足了弱平稳性的第二个条件。

**3. 自协方差 `Cov(Yt, Yt-τ)`:**
推导自协方差稍微复杂一些，但最终可以得到一个简洁的结果（此处我们直接给出结论）：
`Cov(Yt, Yt-τ) = φ^τ * V(Yt) = φ^τ * (σ² / (1 - φ²))`
进一步可以计算自相关系数 `Corr(Yt, Yt-τ)`:
`Corr(Yt, Yt-τ) = Cov(Yt, Yt-τ) / V(Yt) = φ^τ`
*   **结论**:
    *   自协方差和自相关系数都只依赖于时间间隔 `τ`，而与具体的时间点 `t` 无关。这满足了弱平稳性的第三个条件。
    *   AR(1) 模型的自相关函数 (ACF) 呈现出 **指数级衰减** 的模式，衰减的速度由 `|φ|` 的大小决定。

**总结：通过 MA(∞) 表示，我们严格证明了当 `|φ|<1` 时，AR(1) 模型的无条件均值、方差和自协方差结构都是时不变的，因此它是弱平稳的。**

---
### **原创例题与解题思路**

**I. 原Ｏ创例题 (Original Example Question)**

1.  (单选题) 对于平稳 AR(1) 过程 `Yt = 0.8 * Yt-1 + εt`，其 MA(∞) 表示中，滞后3期的随机冲击 `εt-3` 对当前值 `Yt` 的影响权重是多少？
    A. 0.8
    B. 3 * 0.8
    C. 0.8³
    D. 0

2.  (计算题) 假设一个平稳 AR(1) 模型的参数 `φ = 0.5`，随机冲击的方差 `σ² = 4`。请计算该时间序列的无条件方差 `V(Yt)`。

3.  (单选题) 如果一个 AR(1) 模型的自相关系数 `Corr(Yt, Yt-1) = -0.7`，那么这个模型的 `φ` 参数是多少？
    A. 0.7
    B. -0.7
    C. 0.49
    D. -0.49

4.  (判断题) 任何一个 AR(1) 模型都可以被表示为一个 MA(∞) 模型。

5.  (思考题) 为什么说随机游走模型 `Yt = Yt-1 + εt` 无法被写成一个收敛的 MA(∞) 表示？这对它的方差意味着什么？

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: C**。根据 MA(∞) 的公式 `Yt = Σ φ^j * εt-j`，滞后3期的冲击 `εt-3` 对应的 `j=3`。因此其权重是 `φ³`，即 `0.8³ = 0.512`。

2.  **答案: 5.33**。使用无条件方差公式 `V(Yt) = σ² / (1 - φ²)`。
    代入数值：`V(Yt) = 4 / (1 - 0.5²) = 4 / (1 - 0.25) = 4 / 0.75 ≈ 5.33`。

3.  **答案: B**。我们推导出的结论是 `Corr(Yt, Yt-τ) = φ^τ`。对于滞后一期，`τ=1`，所以 `Corr(Yt, Yt-1) = φ¹ = φ`。因此，`φ = -0.7`。

4.  **答案: 错误**。只有 **平稳的** AR(1) 模型（即 `|φ|<1`）才能被表示为 MA(∞) 模型。对于非平稳的 AR(1) 模型（如随机游走），其 MA 表示的系数不会收敛，因此无法写成这种形式。

5.  **答案**:
    *   对于随机游走，`φ=1`。在递归代换到 `J` 步时，表达式为 `Yt = 1^J * Yt-J + Σ(j=0 to J-1) 1^j * εt-j`。
    *   当 `J→∞` 时，第一项 `Yt-J` 的系数永远是1，不会消失。这意味着随机游走永远无法“忘记”其初始状态，它的当前值永远受到无限遥远的过去某个具体值的影响。因此，它无法被写成一个只依赖于过去冲击 `ε` 的收敛级数。
    *   这对它的方差意味着，求和 `Σ (φ²)^j` 变成了 `Σ 1^j`，这个级数是发散的，其和为无穷大。这与我们之前推导出的 `V(Yt) = t * σ²` 是一致的——当 `t→∞` 时，方差也趋于无穷。

---

## 6. 从理想到现实：条件分布与多步预测 (Conditional Distribution & Multi-step Forecasting)

### 6.1. 条件分布 vs. 无条件分布 (Conditional vs. Unconditional Distribution)

*   **无条件分布 F(Yt+h)**: 描述了从现在起 `h` 步之后，那个时间点数值的总体分布，不考虑任何当前信息。
*   **条件分布 F(Yt+h | ℱt)**: 描述了在已知 `t` 时刻及之前所有信息（记为信息集 `ℱt`）的条件下，`h` 步之后数值的分布。

**哪个对预测更重要？**
毫无疑问是 **条件分布**。预测的全部意义就在于利用已知信息 `ℱt` 来缩小对未来的不确定性。

**举例 AR(1) 模型:**
`Yt+1 = φYt + εt+1`
假设 `ε` 服从正态分布 `N(0, σ²)`。
*   **无条件分布**: 我们之前推导出，`Yt+1` 的无条件均值为0，无条件方差为 `σ² / (1 - φ²)`。所以其无功能分布为 `Yt+1 ~ N(0, σ² / (1 - φ²))`。
*   **条件分布**: 在 `t` 时刻，`Yt` 的值（记为 `yt`）是已知的，它不再是一个随机变量，而是一个具体的数字。那么 `Yt+1` 的随机性就只剩下 `εt+1` 这一项。因此，
    *   **条件期望**: `E(Yt+1 | ℱt) = E(φyt + εt+1 | ℱt) = φyt + E(εt+1) = φyt`
    *   **条件方差**: `V(Yt+1 | ℱt) = V(φyt + εt+1 | ℱt) = V(εt+1) = σ²`
    *   所以，其条件分布为 `Yt+1 | ℱt ~ N(φyt, σ²)`。

**关键洞察**:
*   **预测更精确**: `φyt` 是我们对 `Yt+1` 的最佳点预测。
*   **不确定性减小**: 条件方差 `σ²` 总是小于无条件方差 `σ² / (1-φ²)` (因为 `1-φ² < 1`)。这完全符合直觉：当我们拥有更多信息时（知道了 `yt`），对未来的不确定性应该会降低。

### 6.2. 单步与多步预测 (One-step vs. Multi-step Ahead Forecasts)

我们的目标是预测未来 `h` 步的值，即计算条件期望 `E(Yt+h | ℱt)`。

**1. h=1 (一步预测):**
这很简单，我们刚刚已经得到：
`ŷt+1 = E(Yt+1 | ℱt) = φyt`

**2. h=2 (两步预测):**
需要计算 `E(Yt+2 | ℱt)`。直接计算比较困难，因为我们不知道 `Yt+1`。这里需要用到一个强大的工具：**迭代期望定律 (Law of Iterated Expectations)**。

其思想是：对两步之后的期望，等于对“一步之后的一步期望”求期望。
`E(Yt+2 | ℱt) = E [ E(Yt+2 | ℱt+1) | ℱt ]`

*   **内部期望**: `E(Yt+2 | ℱt+1)` 是我们在 `t+1` 时刻做的单步预测，结果是 `φYt+1`。
*   **外部期望**: 现在我们对 `φYt+1` 在 `t` 时刻求期望：
    `E(φYt+1 | ℱt) = φ * E(Yt+1 | ℱt) = φ * (φyt) = φ²yt`

所以，两步预测为 `ŷt+2 = φ²yt`。

**3. h步通用预测公式:**
通过数学归纳法，可以推广得到对未来任意 `h` 步的点预测公式：
`ŷt+h = E(Yt+h | ℱt) = φ^h * yt`

### 6.3. 预测的长期行为

观察这个预测公式 `ŷt+h = φ^h * yt`，可以发现一个有趣的现象：
*   **短期**: 当 `h` 较小时，预测值主要受当前观测值 `yt` 的影响。如果 `yt` 很高，那么 `ŷt+1`, `ŷt+2` 也会比较高。
*   **长期**: 当 `h → ∞` 时，因为 `|φ|<1`，所以 `φ^h → 0`。这意味着 `ŷt+h → 0`。

**解读**:
对于一个平稳的 AR(1) 模型，无论当前值偏离均值多远，我们对遥远未来的预测，最终都会 **回归到序列的无条件均值** (这里是0；对于带常数项的模型，则是回归到 `c/(1-φ)`)。

这完美地体现了“均值回归”的特性：
1.  预测从当前观测值出发。
2.  然后呈指数级衰减，逐渐向长期均值靠拢。
3.  最终，当前信息的“冲击”会完全消散，我们对遥远未来的预测只能是它的平均水平。

### 6.4. 预测的不确定性：预测方差与扇形图 (Forecast Variance & Fan Charts)

点预测只告诉了我们最可能的结果，但没有告诉我们不确定性有多大。需要计算 **h步预测方差** `V(Yt+h | ℱt)`。

经过推导（过程略），可以得到：
`V(Yt+h | ℱt) = σ² * (1 + φ² + φ⁴ + ... + φ²(h-1)) = σ² * Σ(i=0 to h-1) (φ²)^i`

**观察这个公式**:
1.  **方差随 `h` 增大**: 预测的时期越远 (`h` 越大)，累加的项越多，预测方差也越大。这意味着我们对远期预测的不确定性更高。
2.  **方差有上限**: 当 `h → ∞` 时，这个求和收敛于 `1 / (1-φ²)`。所以，`V(Yt+h | ℱt) → σ² / (1-φ²)`。
    *   **解读**: 预测方差永远不会超过序列的 **无条件方差**。最坏的情况下（当我们对遥远的未来一无所知时），我们的不确定性就等于这个序列本身的固有波动性。

这种随预测期 (`h`) 变化的方差，常常用 **扇形图 (Fan Chart)** 来可视化。预测点周围的置信区间（或称 **预测区间 Prediction Intervals**）会随着 `h` 的增大而越来越宽，形成一个扇形，直观地展示了不确定性的增长。

### 6.5. 非平稳模型的预测

*   **随机游走 (φ=1)**:
    *   **预测点**: `ŷt+h = 1^h * yt = yt`。对未来所有时期的最佳预测都是当前值。
    *   **预测方差**: `V(Yt+h | ℱt) = h * σ²`。方差随 `h` 线性增长，**没有上限**。预测的不确定性会无限发散。
*   **带漂移的随机游走 (Yt = c + Yt-1 + εt)**:
    *   **预测点**: `ŷt+h = h*c + yt`。预测是一条斜率为 `c` 的直线。
    *   **预测方差**: `V(Yt+h | ℱt) = h * σ²`。方差同样无限发散。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 对于平稳模型 `Yt = 10 + 0.5 * Yt-1 + εt`，已知 `Yt = 30`。那么对 `Yt+2` 的点预测是多少？
    A. 25
    B. 22.5
    C. 20
    D. 15

2.  (判断题) 对于一个平稳的 AR(1) 过程，我们对一百步之后的预测 (`h=100`) 会比对一步之后的预测 (`h=1`) 更不确定，但其不确定性程度有一个明确的上限。

3.  (单选题) 一个随机游走模型的预测扇形图（Fan Chart）会呈现出什么样的特征？
    A. 宽度保持不变
    B. 宽度先变宽后变窄
    C. 宽度随预测期数的增加而持续、无限制地变宽
    D. 宽度最终收敛到一个固定的最大值

4.  (思考题) 为什么说随机游走的预测是“常数”，而方差是“爆炸”的？这在实际应用中（如预测股价）意味着什么？

5.  (计算题) 已知 AR(1) 过程 `Yt = 0.8Yt-1 + εt`，`εt ~ N(0, 36)`。当前 `Yt = 10`。请计算对 `Yt+2` 的预测区间（假设为95%置信水平，对应的Z值为1.96）。

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。这是一个带常数项的 AR(1) 模型。首先计算其长期均值 `μ = c / (1-φ) = 10 / (1-0.5) = 20`。
    多步预测公式应调整为 `ŷt+h - μ = φ^h * (yt - μ)`。
    `ŷt+2 - 20 = 0.5² * (30 - 20)`
    `ŷt+2 - 20 = 0.25 * 10 = 2.5`
    `ŷt+2 = 22.5`。

2.  **答案: 正确**。预测期越长，`h` 越大，预测方差 `V(Yt+h|ℱt)` 越大，因此不确定性越大。但对于平稳过程，该方差的上限是无条件方差 `σ² / (1-φ²)`，所以不确定性不会无限增长。

3.  **答案: C**。随机游走的 `h` 步预测方差为 `h*σ²`，它随着 `h` 线性增长且没有上限。反映在扇形图上，就是预测区间的宽度会不断地、没有尽头地扩张。

4.  **答案**:
    *   **预测是“常数”**: 指的是点预测 `ŷt+h = yt`。我们对未来任何时间的最佳猜测都只是“停在原地”。这反映了我们无法预测其变动方向的本质。
    *   **方差是“爆炸”的**: 指的是预测方差 `h*σ²` 会随 `h` 无限增大。
    *   **实际意义**: 这意味着，虽然我们对明天股价的最佳猜测是今天的股价，但我们对此猜测的信心会随时间的推移迅速瓦解。可以很肯定地说，一年后的股价不会正好等于今天的股价，但它具体会在哪里，其不确定性（可能范围）会非常非常大。

5.  **答案: [-11.68, 24.48]**
    *   **第一步：计算点预测**
        `ŷt+2 = φ² * yt = 0.8² * 10 = 0.64 * 10 = 6.4`
    *   **第二步：计算预测方差**
        `V(Yt+2 | ℱt) = σ² * (1 + φ²) = 36 * (1 + 0.8²) = 36 * (1 + 0.64) = 36 * 1.64 = 59.04`
    *   **第三步：计算预测标准差**
        `SD = sqrt(59.04) ≈ 7.68`
    *   **第四步：构建预测区间**
        区间 = 点预测 ± Z值 * 标准差
        区间 = `6.4 ± 1.96 * 7.68`
        区间 = `6.4 ± 15.05`
        所以，95%预测区间为 `[-8.65, 21.45]`。（修正计算：`6.4 ± 15.05`，下限为`6.4-15.05 = -8.65`，上限为`6.4+15.05=21.45`）。


---

# 备考复习（Lecture/Tutorial） - Week 3

继上周我们从理论层面探讨了时间序列的基础模型后，本周将卷起袖子，进入预测的“真实战场”。理论上完美的模型，在实际应用中表现如何？我们如何科学地评估并比较不同预测方法的优劣？本周的重点是**预测的验证 (Validation of Forecasts)**，将通过编程实践，掌握一套严谨的、可重复的预测评估流程。

## 1. 预测评估的核心理念：训练集 vs. 验证集 (The Core Idea: Training vs. Validation Set)

### 1.1. 为什么要划分数据集？ (Why Split the Data?)

在建立任何预测模型时，最大的陷阱之一就是 **过拟合 (Overfitting)**。一个模型如果过于复杂，它可能会完美地“记住”历史数据的所有细节，包括那些纯属偶然的噪声。这种模型在解释过去时看起来无懈可击，但在预测未来时却会一败涂地。

为了避免这种情况，我们必须将数据分为至少两部分：
*   **训练集 (Training Set)**: 用于“学习”规律和构建模型的历史数据。
*   **验证集 (Validation Set)** 或 **测试集 (Test Set)**: 模型从未见过的数据，专门用于评估其“真实”的预测能力。

我们在验证集上的表现，才是衡量一个模型泛化能力（即预测未知数据的能力）的“黄金标准”。

### 1.2. 本周案例的评估框架 (The Evaluation Framework in this Tutorial)

本周我们使用澳大利亚联邦银行 (CBA) 的股票收益率数据进行实战。整个评估流程被设计如下：
1.  **数据准备**: 读取CBA的股价数据，并计算每日的百分比收益率 `Returns`。
2.  **设定验证集**: 将使用最后 `n_window = 500` 个数据点作为我们的验证集。这意味着将进行500次独立的预测与评估。
3.  **划分初始训练集**: 除了最后的500个点，之前的所有数据都构成我们的初始训练集。这个初始训练集的长度为 `fw`。

## 2. 预测方案的设计：三种竞争模型 (Designing the Forecasts: Three Competing Models)

在验证流程中，我们设置了三个不同的预测模型进行“同台竞技”。

### 2.1. 基准模型 (Benchmark Model): 历史均值法

*   **预测逻辑**: “未来将与整个历史的平均水平相似”。这是一个非常朴素但稳健的观点。
*   **计算方式**: 在需要预测 `t+1` 时刻的收益率时，我们计算从开始到 `t` 时刻所有已知收益率的样本均值，并将其作为预测值。
*   **代码实现**: `fc_Benchmark = np.mean(cba['Returns'].iloc[1:fw+window+1])`
*   **特点**: 该模型非常稳定，但反应迟钝。如果市场环境发生结构性变化，它需要很长时间才能调整过来。

### 2.2. 模型 A (Forecast A): 微弱记忆模型

*   **预测逻辑**: “明天的收益率会和今天的收益率有一点点关系，但大部分会回归到0”。
*   **计算方式**: `t+1` 时刻的预测值等于 `t` 时刻观测值的10%。
*   **代码实现**: `fc_A = 0.1 * cba['Returns'].iloc[fw+window]`
*   **特点**: 这是一个快速均值回归的模型。它认为任何偏离0的收益率都是暂时的，预测值会迅速向0收缩。

### 2.3. 模型 B (Forecast B): 强烈记忆模型

*   **预测逻辑**: “明天的收益率会和今天的收益率非常相似”。这体现了动量或惯性的思想。
*   **计算方式**: `t+1` 时刻的预测值等于 `t` 时刻观测值的90%。
*   **代码实现**: `fc_B = 0.9 * cba['Returns'].iloc[fw+window]`
*   **特点**: 这是一个具有强“记忆”或高持续性的模型，形式上类似于一个 `φ=0.9` 的AR(1)模型。它认为今天的状态有很大可能会延续到明天。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 将数据集划分为训练集和验证集的主要目的是什么？
    A. 加快模型的计算速度
    B. 评估模型对未知数据的预测能力，以避免过拟合
    C. 确保数据是平稳的
    D. 简化模型的复杂度

2.  (思考题) 假设蜜雪东城要预测明天的奶茶销量。基准模型（历史均值法）预测为300杯，模型B（强烈记忆模型，`φ=0.9`）预测为450杯。如果今天由于商场搞活动，销量飙升到了500杯，请问哪个预测结果更可能是由哪个模型得出的？为什么？

3.  (单选题) 模型A (`fc = 0.1 * y_t`) 和模型B (`fc = 0.9 * y_t`) 的根本区别在于：
    A. 模型A的计算更复杂
    B. 它们对“均值回归”速度的假设不同
    C. 模型B只能用于股票数据
    D. 模型A总是更准确

4.  (判断题) 在本次实验的设定中，基准模型的预测值在整个500天的验证期内是一个固定不变的常数。

5.  (思考题) 如果一个时间序列的真实过程是白噪声（均值为0），那么在模型A、B和基准模型中，哪个模型的长期表现可能会最好？

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。划分数据集的核心目的在于模拟真实世界中的预测场景，即用一个在历史数据上训练好的模型去预测它从未见过的未来数据，从而客观地评估其泛化能力和是否存在过拟合问题。

2.  **答案**: 模型B（`fc=0.9*y_t`）更可能得出450杯的预测。因为它的预测值是今天销量的90%（`0.9 * 500 = 450`）。而历史均值模型通常不会因为一天的突发事件而产生如此剧烈的变化，它的预测值应该更接近长期的平均销量，比如300杯。

3.  **答案: B**。两个模型的核心差异在于对序列“记忆”强度的假设。模型A的系数0.1意味着它认为序列会非常迅速地回归到其均值（这里是0）。模型B的系数0.9则认为序列具有很强的持续性，回归均值的速度很慢。

4.  **答案: 错误**。在“扩展窗口”的设定下，基准模型的预测值是变化的。每预测完一天，这个新的观测值就会被加入到历史数据中，用于计算下一个预测日的历史均值。因此，这个均值是在缓慢更新的。

5.  **答案**: 模型A可能会表现最好。因为白噪声序列的真实值 `y_t+1` 与 `y_t` 无关，其期望为0。模型A的预测 `0.1 * y_t` 会迅速向0靠拢，与白噪声的特性相符。模型B的预测会错误地追随前一天的随机波动。基准模型的预测均值也会在0附近，但可能不如模型A灵活。

---

## 3. 动态评估方法（一）：扩展窗口法 (Dynamic Evaluation I: Expanding Window)

### 3.1. 什么是扩展窗口？

扩展窗口是一种模拟“信息不断积累”过程的评估方法。它的工作流程如下：
1.  **初始**: 使用初始训练集（例如，第1到1000天的数据）来生成对第1001天的预测。
2.  **评估**: 将预测值与第1001天的真实值进行比较，计算预测误差。
3.  **扩展**: 将第1001天的真实数据 **加入** 到训练集中。现在我们的训练集包含了第1到1001天的数据。
4.  **迭代**: 使用新的、更大的训练集来生成对第1002天的预测，然后重复此过程，直到走完整个验证集。

**核心思想**: 随着时间的推移，我们可用的信息越来越多，模型在做决策时应该利用所有已知信息。

### 3.2. 代码逻辑解析

在教程的 `for` 循环中，这一思想体现得淋漓尽致：
*   `y_t1 = cba['Returns'].iloc[fw+window+1]`: 获取验证集中当前需要预测的真实值。
*   `fc_Benchmark = np.mean(cba['Returns'].iloc[1:fw+window+1])`: 计算均值时，数据的上界 `fw+window+1` 随着 `window` 的增加而向右扩展，完美体现了“扩展”的概念。
*   `RMSE_Benchmark += (y_t1-fc_Benchmark)**2.0`: 累加平方误差，用于后续计算RMSE。

## 4. 动态评估方法（二）：滚动窗口法 (Dynamic Evaluation II: Rolling Window)

### 4.1. 什么是滚动窗口？

与扩展窗口不同，滚动窗口的训练集大小是 **固定** 的。它的工作流程如下：
1.  **初始**: 使用一个固定大小的训练集（例如，过去2000天的数据）来生成对今天的预测。
2.  **评估**: 比较预测与真实值。
3.  **滚动**: 将今天的新数据加入训练集，并 **同时丢弃训练集中最老的一天的数据**，从而保持训练集大小不变。
4.  **迭代**: 使用这个“更新”后的训练集来预测明天。

**核心思想**: “远古”的历史数据可能已经不再适用，我们应该更关注于近期的数据规律。这对于可能存在 **结构性突变 (Structural Breaks)** 的时间序列尤为重要。

### 4.2. 代码逻辑解析

教程中实现滚动窗口的关键改动只有一行：
`fc_Benchmark = np.mean(cba['Returns'].iloc[fw+window-T_train+1:(fw+window+1)])`
这里，切片的起点 `fw+window-T_train+1` 和终点 `fw+window+1` 都在随着 `window` 移动，两者之差始终是固定的 `T_train`。这就实现了“窗口”在时间轴上的“滚动”。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 扩展窗口和滚动窗口评估方法的主要区别在于：
    A. 使用的预测模型不同
    B. 滚动窗口的计算速度更快
    C. 用于生成预测的训练集大小是否随时间变化
    D. 扩展窗口只能用于平稳序列

2.  (思考题) 蜜雪东城在2020年之前主打低价策略，之后品牌升级，开始推出高端水果茶系列。现在是2023年，如果要为他们的销售额数据选择一个预测评估方案，你更倾向于扩展窗口还是滚动窗口？为什么？

3.  (判断题) 在本次教程中，对于模型A (`fc=0.1*y_t`) 和模型B (`fc=0.9*y_t`)，使用扩展窗口或滚动窗口对它们的预测结果没有影响。

4.  (单选题) 在一个非常稳定、规律从未改变的时间序列上，哪种评估方法可能更有优势？
    A. 滚动窗口，因为它更灵活
    B. 扩展窗口，因为它可以利用更长的历史信息来获得更稳健的参数估计
    C. 两者没有区别
    D. 无法判断

5.  (思考题) 实现一个大小为100的滚动窗口，当前是第500次预测，数据索引从0开始。请问用于计算基准模型预测值的Python数据切片应该是什么？假设初始训练窗口 `fw` 之后是验证集。

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: C**。这是两者最本质的区别。扩展窗口的训练集大小 (`N`) 随时间 `t` 线性增长 (`Nt = N0 + t`)，而滚动窗口的训练集大小始终保持为一个常数 `T_train`。

2.  **答案**: 更倾向于 **滚动窗口**。因为公司在2020年发生了明显的“结构性突变”（经营策略改变）。2020年之前的低价策略时期的数据规律，可能对于预测现在以高端产品为主的销售额不再具有代表性，甚至可能产生误导。滚动窗口可以舍弃这些陈旧信息，更专注于近期的市场环境。

3.  **答案: 正确**。这两个模型的预测值都只依赖于前一天的观测值 (`y_t`)，而与更早的历史数据无关。因此，无论训练集是扩展还是滚动，只要 `y_t` 是确定的，它们的预测结果 `fc_A` 和 `fc_B` 就是一样的。窗口类型主要影响的是基准模型这类需要利用一段历史数据进行计算的模型。

4.  **答案: B**。如果序列的内在规律（如均值、方差等）非常稳定，那么数据越多，我们对这些规律的估计就越精确。扩展窗口利用了全部历史信息，可以得到更稳健的统计估计（如样本均值），因此可能表现更好。

5.  **答案**:
    *   当前预测是第 `window = 499` 次（因为从0开始计数）。
    *   预测目标是 `y_{t+1}`，其索引是 `fw + window + 1`。
    *   使用的最后一个数据点是 `y_t`，其索引是 `fw + window`。
    *   滚动窗口大小为 `T_train = 100`。
    *   切片的终点是 `fw + window + 1` (不包含)。
    *   切片的起点是 `(fw + window + 1) - 100`。
    *   所以切片是 `data.iloc[(fw+499+1)-100 : fw+499+1]`，即 `data.iloc[fw+400 : fw+500]`。

---
我已完成对动态评估窗口方法的精讲。接下来的内容将聚焦于如何量化评估结果，并判断模型之间的优劣差异是否具有统计显著性。是否需要我继续生成后续的部分？

我们进入最后一部分，也是整个预测评估流程的“审判”环节。

已经通过扩展窗口或滚动窗口，为验证集中的每一个时间点生成了来自三个不同模型的预测值。现在我们手头有三组成绩单，接下来需要回答两个核心问题：
1.  **“谁考得最好？”** —— 这需要一个客观的评分标准来量化预测的准确度。
2.  **“考得好是凭实力还是凭运气？”** —— 即使一个模型的评分略高，我们如何确定这种优势是系统性的，而不是由几次偶然的幸运预测造成的？

---

## 5. 评价预测优劣（一）：准确度度量 (Measuring Forecast Accuracy)

为了量化预测的准确性，需要一个 **损失函数 (Loss Function)** 来衡量预测误差。在本次教程中，我们使用的核心度量是 **均方根误差 (Root Mean Squared Error, RMSE)**。

### 5.1. 均方根误差 (RMSE)

*   **计算逻辑**:
    1.  **计算误差**: `et+1 = yt+1 - ŷt+1` (真实值 - 预测值)
    2.  **误差平方**: `(et+1)²`。平方有两个好处：(a) 使得所有误差都为正，避免正负抵消；(b) 对较大的误差给予更重的惩罚。
    3.  **计算均值**: 对验证集里所有的平方误差求平均值，得到 **均方误差 (Mean Squared Error, MSE)**。
        `MSE = (1/N) * Σ(et+1)²`
    4.  **开方**: 将MSE开方，得到RMSE。
        `RMSE = sqrt(MSE)`
        开方的目的是让误差的单位与原始数据的单位保持一致，更便于解释。

*   **解读**: RMSE越小，说明模型的预测值整体上与真实值的偏差越小，预测越准确。

*   **代码实现**:
    `RMSE_Benchmark = np.sqrt(RMSE_Benchmark/n_window)`
    这里的 `RMSE_Benchmark` 变量在循环中累加的是平方误差，所以在循环结束后，先除以窗口数 `n_window` 得到MSE，再用 `np.sqrt()` 开方得到RMSE。

### 5.2. 实验结果分析

从教程的输出结果来看（无论是扩展窗口还是滚动窗口），我们通常会看到：
*   **模型A (微弱记忆)** 和 **基准模型 (历史均值)** 的RMSE非常接近，且数值较低。
*   **模型B (强烈记忆)** 的RMSE显著高于前两者。

**初步结论**:
模型B的表现最差。它试图去“追踪”每日的波动，但由于股票收益率的波动很大程度上是随机的，这种追踪反而引入了更大的误差。相反，模型A和基准模型采取了更“保守”的策略（预测值接近于0或长期均值），在一个充满噪声的数据上，这种策略反而更稳健。

**视觉陷阱**:
教程中特别提到，直接绘制预测值和真实值的曲线图可能会产生误导。模型B的预测曲线看起来和真实值曲线“更同步”，似乎在“追踪”数据，而模型A和基准模型的预测线则像一条平坦的直线。然而，RMSE告诉我们，看似“努力”的模型B，其累积误差远大于那些“躺平”的模型。这教育我们：**不能仅凭肉眼观察来评判预测好坏，必须依赖于量化的准确度指标。**

## 6. 评价预测优劣（二）：统计显著性检验 (Testing for Statistical Significance)

现在我们知道模型A和基准模型的RMSE差不多，都优于模型B。但问题来了：模型A比基准模型的RMSE低了那么一点点（例如，1.2879 vs 1.2887），这个微小的优势是真实存在的，还是仅仅是样本内的随机波动？

为了回答这个问题，需要进行 **Diebold-Mariano (DM) 检验**。

### 6.1. Diebold-Mariano (DM) 检验

*   **核心思想**: DM检验用于判断两个模型的预测准确度是否存在 **统计上的显著差异**。它不是直接比较RMSE的大小，而是检验两个模型预测误差序列的差异是否系统性地不为零。

*   **检验步骤**:
    1.  获取两个模型的预测误差序列：`e1_t` (模型A的误差) 和 `e2_t` (基准模型的误差)。
    2.  定义一个损失差异序列 `d_t = L(e1_t) - L(e2_t)`。在这里，损失函数 `L` 是平方损失，即 `d_t = (e1_t)² - (e2_t)²`。
    3.  **原假设 (H0)**: 两个模型的预测准确度没有差异。这意味着损失差异序列 `d_t` 的期望值为0 (`E(d_t) = 0`)。
    4.  **备择假设 (H1)**: 两个模型的预测准确度存在差异 (`E(d_t) ≠ 0`)。
    5.  DM检验会计算一个统计量，并给出对应的 **p-value**。

*   **p-value 的解读**:
    *   **p-value > 0.05 (或0.1)**: 我们 **没有足够证据拒绝原假设**。这意味着，即使两个模型的RMSE在样本中看起来不同，这种差异在统计上是不显著的，很可能是由随机性造成的。我们不能断定一个模型就比另一个好。
    *   **p-value < 0.05**: 可以 **拒绝原假设**。这意味着两个模型预测准确度的差异是显著的，模型之间存在真实的优劣之分。

### 6.2. 单边检验 vs. 双边检验 (One-sided vs. Two-sided Test)

*   **双边检验 (two-sided, `one_sided=False`)**:
    *   备择假设 H1: “模型A的准确度 **不等于** 基准模型”。
    *   它只关心两者是否有差异，不关心谁更好。
*   **单边检验 (one-sided, `one_sided=True`)**:
    *   备择假设 H1: “模型A的准确度 **优于** 基准模型”。
    *   这是一种更具体、更强的假设。当有一个明确的基准，并想证明新模型是否能“击败”它时，单边检验更有意义。

### 6.3. 实验结果解读

*   **模型A vs. 基准模型**:
    *   双边检验的 p-value 约为0.91。这是一个非常大的值，远高于0.05。
    *   **结论**: 我们完全不能拒绝原假设。模型A和基准模型之间的准确度差异是 **不显著** 的。
*   **模型B vs. 基准模型**:
    *   双边检验的 p-value 趋近于0 (例如, 2.7e-10)。这是一个极小的值。
    *   **结论**: 可以强烈地拒绝原假设。模型B和基准模型之间的准确度差异是 **高度显著** 的。结合RMSE可知，基准模型显著优于模型B。

## 7. 挑战升级：多步预测评估 (Multistep Ahead Forecasts Evaluation)

现实中的预测任务往往不是只预测下一步，而是需要预测未来多个时期（例如，未来5天）。

### 7.1. 多步预测的评估框架

*   **挑战**: 需要对每个预测期 (`h = 1, 2, ..., H`) 分别进行评估。
*   **设置**: 在教程中，我们设定最大预测期 `H=5`。在验证集的每一次循环中，我们不再是预测 `y_{t+1}`，而是同时生成对 `y_{t+1}, y_{t+2}, ..., y_{t+5}` 的预测。
    *   **注意**: 在这个简化的例子中，我们用同一个预测值（基于`t`时刻信息）来作为未来所有5步的预测。这在实际中比较粗糙，但便于我们理解评估框架。
*   **数据存储**: 预测值和真实值不再是向量，而是变成了矩阵（`n_window * H`）。每一列对应一个特定的预测期（h=1, h=2, ...）。
*   **独立评估**: 我们为每个预测期 `h` 单独计算RMSE。最终会得到一个包含 `H` 个RMSE值的向量，分别代表模型在1步、2步、...、H步预测上的表现。

### 7.2. 实验结果解读

输出结果显示了每个模型在 `h=1` 到 `h=5` 的RMSE。
`[1.2899, 1.2891, 1.2888, 1.2897, 1.2896]`
这五个数字分别代表了基准模型在1步到5步预测上的RMSE。

通过比较不同模型在同一列（同一预测期）的RMSE，可以判断在特定预测期上哪个模型更优。教程的结论是：模型A和基准模型轮流在不同期上取得最佳表现，而模型B在所有期上都是最差的。同样，可以（也应该）对每个预测期 `h` 进行DM检验，来判断这些优劣差异是否显著。

---
### **原创例题与解题思路**

**I. 原创例题 (Original Example Question)**

1.  (单选题) 如果模型A的RMSE为1.5，模型B的RMSE为2.5，可以得出什么初步结论？
    A. 模型A的预测值总是比模型B的低
    B. 模型A的预测准确度优于模型B
    C. 模型B存在过拟合问题
    D. 两个模型都不好

2.  (判断题) 在DM检验中，如果p-value为0.04，可以认为两个模型的预测能力确实存在显著差异。

3.  (思考题) 蜜雪东城开发了一个新的、复杂的奶茶销量预测AI模型，其RMSE为20.5。而简单的历史均值法的RMSE为21.0。在进行DM检验后，得到的p-value为0.25。作为数据分析师，你会建议公司立即用新AI模型替换旧方法吗？为什么？

4.  (单选题) 在进行多步预测评估时，为什么需要为每个预测期 `h` 单独计算RMSE？
    A. 因为不同期的真实值不同
    B. 这样做可以简化代码
    C. 因为一个模型可能在短期预测上表现优异，但在长期预测上表现糟糕，需要分开评估
    D. 这是DM检验的要求

5.  (思考题) 在多步预测中，一个模型的RMSE向量为 `[1.2, 1.5, 1.8, 2.2, 2.5]`。这个RMSE不断增大的趋势说明了什么？

**II. 解题思路 (Solution Walkthrough)**

1.  **答案: B**。RMSE是衡量预测准确度的指标，值越小代表准确度越高。因此，RMSE为1.5的模型A优于RMSE为2.5的模型B。

2.  **答案: 正确**。p-value为0.04小于常用的显著性水平0.05，因此有足够证据拒绝“两个模型没有差异”的原假设，从而认为它们之间存在统计上显著的性能差异。

3.  **答案**: 不会建议立即替换。尽管新AI模型的样本内RMSE（20.5）略低于旧方法（21.0），但DM检验的p-value为0.25，远大于0.05。这表明这个微小的优势在统计上是不显著的，很可能只是随机出现的。在没有证据表明新模型能带来“真正”的、系统性的提升之前，考虑到新模型的复杂性、维护成本等因素，贸然替换是不明智的。

4.  **答案: C**。模型的预测能力往往会随预测期的变化而变化。例如，一个捕捉动量的模型可能在1步预测上很准，但随着时间推移，动量消失，其长期预测会变差。而均值回归模型可能短期表现一般，但长期预测更稳健。因此，必须对每个`h`进行独立评估，以全面了解模型的特性。

5.  **答案**: 这个趋势是完全正常的，并且几乎在所有模型中都会出现。它说明了 **预测的不确定性会随着预测期的增长而增加**。我们对明天的预测通常比对下周的预测更有把握，对下周的又比对下个月的更有把握。RMSE作为误差的度量，其随 `h` 增大正反映了这种常识。

---

## B. 更多练习题 (More Practice Questions)

Since the provided tutorial material is a code walkthrough and does not contain a formal set of practice questions, this section consists of 15 newly created original questions. They are designed to cover the core concepts from both the lecture and the tutorial, testing your understanding of forecast validation, model properties, and the interpretation of statistical results.

**Original Practice Questions**

1.  A time series exhibits a major structural break in its mean due to a policy change halfway through the dataset. When setting up a forecast validation scheme, which method is generally more appropriate for the period after the break, and why?
    (A) Expanding window, because it uses more data which is always better.
    (B) Rolling window, because it can discard the outdated data from before the policy change.
    (C) Both are equally effective.
    (D) Neither, a new model must be built from scratch.

2.  You are comparing two forecasts, Model X and Model Y. Their RMSEs on a validation set of 100 observations are 10.5 and 10.8, respectively. The Diebold-Mariano test for the null hypothesis of equal predictive accuracy yields a p-value of 0.35. What is the most appropriate conclusion?
    (A) Model X is significantly better than Model Y.
    (B) Model Y is significantly better than Model X.
    (C) There is no statistically significant difference in the predictive accuracy of the two models.
    (D) Both models are inaccurate because their RMSEs are high.

3.  Consider the AR(1) model `Yt = 0.6 * Yt-1 + εt`, where `εt` is white noise with variance `σ² = 9`. What is the unconditional variance of `Yt`?
    (A) 9
    (B) 14.06
    (C) 22.5
    (D) 5.625

4.  In the tutorial's multistep forecast evaluation, the forecasts and actuals were stored in matrices of shape `(n_window, H)`. If we want to perform a DM test to compare Model A and Model B's 3-step ahead forecasts, which data should be used?
    (A) The entire `allfc_A` and `allfc_B` matrices.
    (B) The third row of the `allfc_A` and `allfc_B` matrices.
    (C) The third column of the `allfc_A` and `allfc_B` matrices, and the third column of the actuals matrix.
    (D) The mean of all forecasts in the matrices.

5.  A forecast for a stock's daily return is given by `ŷt+h = 0.05`. The actual return on day `t+h` is `-0.10`. What is the squared error for this specific forecast?
    (A) -0.15
    (B) 0.15
    (C) 0.0225
    (D) 0.0025

6.  Which of the following processes is non-stationary and will have a forecast variance that grows linearly with the forecast horizon `h`?
    (A) A white noise process.
    (B) `Yt = 25 + 0.2 * Yt-1 + εt`
    (C) `Yt = Yt-1 + εt`
    (D) `Yt = -0.9 * Yt-1 + εt`

7.  When visually inspecting a plot of forecasts, a forecast series that closely "tracks" the volatile movements of the actual series always indicates a better model than a flatter forecast series. Is this statement True or False?

8.  For a stationary AR(1) process with `Yt = 10` and `φ = 0.8`, what is the 3-step ahead point forecast, `E(Yt+3 | ℱt)`?
    (A) 8.0
    (B) 6.4
    (C) 5.12
    (D) 10.0

9.  The primary purpose of calculating returns from asset prices (e.g., `100 * (Pt - Pt-1) / Pt-1`) for time series modeling is often to:
    (A) Make the numbers smaller and easier to handle.
    (B) Induce stationarity in the data, as prices are often non-stationary while returns are closer to stationary.
    (C) Remove the need for a validation set.
    (D) Ensure the data is always positive.

10. You perform a one-sided DM test with the alternative hypothesis that "Model A is more accurate than the Benchmark". The test yields a p-value of 0.03. What does this imply?
    (A) The benchmark is significantly more accurate than Model A.
    (B) We have statistically significant evidence that Model A is more accurate than the benchmark.
    (C) The models are not significantly different.
    (D) The test was performed incorrectly.

11. If a time series is truly a white noise process `εt`, what would be the optimal long-term point forecast `E(εt+h | ℱt)` for `h → ∞`?
    (A) `εt`
    (B) 1
    (C) `σ²`
    (D) 0

12. In the Python `for` loop of the expanding window in the tutorial, the slice used for the benchmark forecast is `iloc[1:fw+window+1]`. What does the `fw+window+1` part represent?
    (A) It ensures the loop runs one extra time.
    (B) It is the index of the current observation `yt+1` being predicted.
    (C) It marks the end of the current training data available for making the forecast.
    (D) It is a typo and should be `fw+window`.

13. For a random walk with drift `Yt = 2 + Yt-1 + εt`, if `Yt = 100`, what is the point forecast for `Yt+5`?
    (A) 100
    (B) 102
    (C) 110
    (D) Cannot be determined.

14. Two models produce the exact same RMSE value on a validation set. The DM test p-value will be:
    (A) Exactly 0
    (B) Exactly 1
    (C) Exactly 0.5
    (D) Close to 1, but not necessarily exactly 1.

15. The h-step ahead forecast variance for a stationary AR(1) model `V(Yt+h | ℱt)` is always less than or equal to the unconditional variance `V(Yt)`. Why does this make intuitive sense?
    (A) Because forecasting becomes easier over longer horizons.
    (B) Because knowing the present (`ℱt`) should, at worst, provide no information about the future, but it cannot increase our uncertainty beyond the series' inherent randomness.
    (C) Because the conditional variance is always zero.
    (D) Because the unconditional variance grows with time.

## C. 练习题答案 (Practice Question Answers)

1.  **题号与核心概述**: 1. 窗口选择与结构突变
    *   **答案**: (B)
    *   **解析**: 滚动窗口通过丢弃最旧的数据来保持训练集大小不变。当数据存在结构性突变时（如经营策略改变），旧数据的规律可能不再适用于新时期。滚动窗口能够“忘记”这些过时的信息，更专注于近期的模式，因此是更合适的选择。扩展窗口会永久保留旧数据，可能会被过时信息污染。

2.  **题号与核心概述**: 2. DM检验结果解读
    *   **答案**: (C)
    *   **解析**: 尽管模型X的样本RMSE（10.5）略低于模型Y（10.8），但DM检验的原假设是“两个模型预测准确度相等”。p-value为0.35，远大于0.05或0.1等常用的显著性水平。这意味着我们没有足够的统计证据来拒绝原假设。因此，我们不能认为模型X的微弱优势是系统性的，两者准确度没有统计上的显著差异。

3.  **题号与核心概述**: 3. AR(1)无条件方差计算
    *   **答案**: (B)
    *   **解析**: 对于一个平稳的AR(1)模型 `Yt = φYt-1 + εt`，其无条件方差的公式为 `V(Yt) = σ² / (1 - φ²)`。
        将 `φ = 0.6` 和 `σ² = 9` 代入：
        `V(Yt) = 9 / (1 - 0.6²) = 9 / (1 - 0.36) = 9 / 0.64 = 14.0625`。

4.  **题号与核心概述**: 4. 多步预测数据提取
    *   **答案**: (C)
    *   **解析**: 多步预测的评估是对每个预测期 `h` 独立进行的。要比较3步预测（h=3）的准确性，需要提取所有与h=3相关的预测和真实值。在 `(n_window, H)` 形状的矩阵中，行代表每一次预测，列代表预测期。因此，需要的是两个模型预测矩阵的第3列以及真实值矩阵的第3列。

5.  **题号与核心概述**: 5. 平方误差计算
    *   **答案**: (C)
    *   **解析**: 平方误差的计算公式为 `(真实值 - 预测值)²`。
        `Error = -0.10 - 0.05 = -0.15`
        `Squared Error = (-0.15)² = 0.0225`。

6.  **题号与核心概述**: 6. 非平稳性与预测方差
    *   **答案**: (C)
    *   **解析**: 选项(C) `Yt = Yt-1 + εt` 是随机游走模型（AR(1)中`φ=1`），它是非平稳的。其h步预测方差为 `V(Yt+h | ℱt) = h * σ²`，该方差随预测期 `h` 线性增长。其他选项都是平稳过程，其预测方差会收敛于无条件方差。

7.  **题号与核心概述**: 7. 预测图的视觉陷阱
    *   **答案**: False
    *   **解析**: 正如教程中强调的，这是一种常见的视觉陷阱。对于充满噪声的序列（如股票收益率），一个试图追踪每一个随机波动的模型（如模型B）往往会产生比一个更平滑、更保守的模型（如历史均值法）更大的累积误差（RMSE）。因此，不能仅凭视觉上的“追踪”程度来判断模型优劣。

8.  **题号与核心概述**: 8. AR(1)多步预测计算
    *   **答案**: (C)
    *   **解析**: 对于一个不含常数项的平稳AR(1)模型，其h步向前预测的公式为 `E(Yt+h | ℱt) = φ^h * yt`。
        将 `h=3`, `φ=0.8`, `yt=10` 代入：
        `ŷt+3 = 0.8³ * 10 = 0.512 * 10 = 5.12`。

9.  **题号与核心概述**: 9. 计算收益率的目的
    *   **答案**: (B)
    *   **解析**: 绝大多数金融资产的价格序列都是非平稳的（类似于随机游走），直接对其建模很困难。而资产的收益率序列通常更接近于平稳（围绕一个均值波动），这使得许多标准时间序列模型（如AR模型）可以直接应用。因此，计算收益率是处理金融时间序列时为了获得平稳性的常用预处理步骤。

10. **题号与核心概述**: 10. 单边DM检验解读
    *   **答案**: (B)
    *   **解析**: p-value为0.03，小于显著性水平0.05。这意味着可以拒绝原假设（两者准确度相等）。由于这是一个单边检验，其备择假设是“模型A更优”，因此这个显著的结果支持了备择假设。有统计证据表明模型A的预测准确度显著优于基准模型。

11. **题号与核心概述**: 11. 白噪声的长期预测
    *   **答案**: (D)
    *   **解析**: 白噪声过程的定义是 `E(εt) = 0` 且 `Cov(εt, εs) = 0` for `t≠s`。这意味着过去的值对未来没有任何预测能力。因此，对未来任何时刻的最佳点预测都是其无条件均值，即0。

12. **题号与核心概述**: 12. Python代码切片逻辑
    *   **答案**: (C)
    *   **解析**: 在Python中，`iloc` 切片是“包头不包尾”的。`fw+window` 是当前时间点 `t` 的索引。为了在预测 `t+1` 时使用截至 `t` 的所有数据，数据切片的终点需要是 `t` 的索引加1，即 `fw+window+1`。因此，它标志着当前可用训练数据的结束边界。

13. **题号与核心概述**: 13. 带漂移随机游走预测
    *   **答案**: (C)
    *   **解析**: 对于带漂移的随机游走 `Yt = c + Yt-1 + εt`，其h步预测公式为 `ŷt+h = h*c + yt`。
        将 `h=5`, `c=2`, `yt=100` 代入：
        `ŷt+5 = 5 * 2 + 100 = 10 + 100 = 110`。

14. **题号与核心概述**: 14. DM检验的特殊情况
    *   **答案**: (D)
    *   **解析**: 如果两个模型的RMSE完全相同，这意味着它们的平均平方误差也完全相同。然而，DM检验是基于损失差异序列 `d_t` 的，即使总体MSE相同，`d_t` 序列也可能存在自相关等结构。在大多数标准实现下，如果误差序列完全相同，p-value会非常接近1，但不保证严格等于1。如果只是RMSE相同但误差序列不同，p-value也会很高。

15. **题号与核心概述**: 15. 条件与无条件方差
    *   **答案**: (B)
    *   **解析**: 无条件方差代表了我们对这个序列一无所知时的不确定性程度（即其固有的、长期的波动性）。条件方差是在我们知道了当前所有信息 `ℱt` 后的不确定性。信息的作用是用来降低不确定性的。在最差的情况下，当前信息对遥远的未来毫无帮助，此时我们的不确定性就回退到无条件方差的水平。但信息绝不可能凭空增加我们对未来的不确定性。
---

