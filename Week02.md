# 备考复习 (Lecture) - Week 2

## 1. 评估预测的核心问题 (The Core Problem of Forecast Evaluation)

### 1.1. 为什么预测需要“评估”？ (Why Do Forecasts Need Evaluation?)

在商业和金融领域，我们做预测的最终目的是为了做出更优的决策。例如，一家公司预测下个季度的销售额，是为了更好地规划生产和库存。一个投资者预测某支股票的未来回报，是为了决定是否买入。

然而，对于任何一个不确定的未来事件，我们都可以做出多种不同的预测。

想象一个游戏：你支付 ￥2 参与，游戏会从一个特定的概率分布（指数分布）中抽取一个数字 `Y`，然后你将得到 `￥Y`。为了决定这个赌局是否值得，你需要预测 `Y` 的可能结果。

你应该预测 `Y` 的平均值（期望值）？还是 `Y` 的中位数？或是其他某个数值？

这个问题的关键在于：**不存在一个放之四海而皆准的“最佳”预测。** 一个预测的好坏，完全取决于你评估它的“标准”是什么。这个“标准”，在统计学和计量经济学中，就是 **损失函数 (Loss Function)**。它定义了当你的预测偏离真实结果时，你会“损失”多少。

### 1.2. 损失函数 (Loss Function)

损失函数是一个明确的规则，它像一个惩罚机制，用来量化预测错误带来的成本。

*   **定义**：损失函数 `L(y, ŷ)` 接收两个输入：真实发生的观测值 `y` 和你的预测值 `ŷ`。它输出一个非负数，代表这次预测的“损失”或“成本”。
*   **核心思想**：损失值越高，代表你的预测表现越差。一个完美的预测（`y = ŷ`）的损失值为 0。
*   **数学表达**: `L: I² → R⁺`，其中 `I` 是结果 `Y` 可能取值的范围，`R⁺` 代表所有非负实数。

没有上下文，就没有对错。只有当我们明确了损失函数，也就是定义了我们“关心”的误差类型之后，我们才能找到一个“最优”的预测。

---
## 2. 核心评估工具：损失函数与误差度量 (The Toolkit: Loss Functions & Error Metrics)

在实践中，我们最常用两类损失函数，它们对应着两种衡量总体预测表现的误差度量指标 (Error Metrics)。

### 2.1. 平方损失 (Quadratic Loss) 与 均方根误差 (RMSE)

*   **知识点：平方损失函数 (Quadratic / L2 Loss Function)**
    *   **概念阐释**: 这是最常用的损失函数之一。它计算了真实值与预测值之差的平方。
    *   **公式呈现**:
        `L(y, ŷ) = (y - ŷ)²`
    *   **核心特点**: 这种函数对较大的误差给予了不成比例的、非常高的“惩罚”。例如，差值为 2 的误差，其损失是 4；但差值为 10 的误差，其损失高达 100。这意味着，使用平方损失作为评估标准时，模型会极力避免出现离谱的极端错误。

*   **知识点：均方根误差 (Root Mean Squared Error, RMSE)**
    *   **概念阐释**: 当我们进行多次预测后（例如，预测未来100天的股票收益），我们需要一个总体的指标来衡量模型的表现。RMSE 就是基于平方损失的总体误差度量。它计算的是一系列损失的平均值的平方根。
    *   **公式呈现**:
        `RMSE = \sqrt{\frac{1}{S} \sum_{t=1}^{S} (y_t - \hat{y}_t)^2}`
        其中 `S` 是预测的总次数，`y_t` 是第 `t` 次的真实值，`ŷ_t` 是第 `t` 次的预测值。
    *   **举个例子**: 假设“蜜雪东城”奶茶店预测了连续3天的日销量，情况如下：
        *   第一天：真实销量 100 杯，预测销量 110 杯，误差 = -10，平方损失 = 100
        *   第二天：真实销量 150 杯，预测销量 145 杯，误差 = 5，平方损失 = 25
        *   第三天：真实销量 120 杯，预测销量 140 杯，误差 = -20，平方损失 = 400
    *   **计算过程全景展示**:
        1.  **公式呈现**: `RMSE = \sqrt{\frac{1}{3} \sum_{t=1}^{3} (y_t - \hat{y}_t)^2}`
        2.  **案例代入**: `RMSE = \sqrt{\frac{1}{3} (100 + 25 + 400)}`
        3.  **计算步骤拆解**:
            *   计算平方损失之和：`100 + 25 + 400 = 525`
            *   计算平均平方损失：`525 / 3 = 175`
            *   开方：`\sqrt{175} ≈ 13.23`
        4.  **结果解读**: RMSE 的结果（13.23杯）与原始数据（销量）的单位是相同的。这使得它比平均平方损失（175）更具解释性。我们可以直观地说，模型的平均预测误差大约在 13.23 杯的量级。

### 2.2. 绝对损失 (Absolute Loss) 与 平均绝对误差 (MAE)

*   **知识点：绝对损失函数 (Absolute / L1 Loss Function)**
    *   **概念阐释**: 这种损失函数计算真实值与预测值之差的绝对值。
    *   **公式呈现**:
        `L(y, ŷ) = |y - ŷ|`
    *   **核心特点**: 绝对损失对所有误差（无论大小）都给予线性的、同等的“惩罚”。误差为 10 的损失就是 10，误差为 2 的损失就是 2。与平方损失相比，它对极端异常值 (outliers) 不那么敏感。

*   **知识点：平均绝对误差 (Mean Absolute Error, MAE)**
    *   **概念阐释**: MAE 是基于绝对损失的总体误差度量，它计算的是一系列绝对损失的算术平均值。
    *   **公式呈现**:
        `MAE = \frac{1}{S} \sum_{t=1}^{S} |y_t - \hat{y}_t|`
    *   **举个例子**: 沿用“蜜雪东城”的例子：
        *   第一天：真实销量 100 杯，预测销量 110 杯，绝对损失 = 10
        *   第二天：真实销量 150 杯，预测销量 145 杯，绝对损失 = 5
        *   第三天：真实销量 120 杯，预测销量 140 杯，绝对损失 = 20
    *   **计算过程全景展示**:
        1.  **公式呈现**: `MAE = \frac{1}{3} \sum_{t=1}^{3} |y_t - \hat{y}_t|`
        2.  **案例代入**: `MAE = \frac{1}{3} (10 + 5 + 20)`
        3.  **计算步骤拆解**:
            *   计算绝对损失之和：`10 + 5 + 20 = 35`
            *   计算平均绝对损失：`35 / 3 ≈ 11.67`
        4.  **结果解读**: MAE 的结果（11.67杯）同样与原始数据的单位相同。它告诉我们，模型平均而言会高估或低估约 11.67 杯。

### 2.3. 原创例题

I. 原创例题 (Original Example Question)
1.  (选择题) 某金融分析师在评估两个股票价格预测模型时发现，模型A偶尔会出现一次非常离谱的预测错误，但大部分时间都比较准；模型B则从未有过极端错误，但其日常的小误差比模型A略多。如果该分析师的首要目标是**避免任何一次性的重大预测失误**，他应该优先选择哪个评估指标来挑选模型？
    A. MAE (平均绝对误差)
    B. RMSE (均方根误差)
    C. 两者皆可，没有区别
    D. 无法判断

2.  (选择题) 对于同一组预测值和真实值，如果 RMSE 的值远大于 MAE 的值，这通常暗示着什么？
    A. 预测值系统性地高于真实值
    B. 预测值系统性地低于真实值
    C. 数据中存在一些导致巨大误差的离群值 (outliers)
    D. 所有的预测误差都非常小且均匀分布

3.  (计算题) 某天气预报连续4天预测了最高气温，真实值和预测值（摄氏度）分别为：(真实: 25, 预测: 27), (真实: 28, 预测: 28), (真实: 30, 预测: 26), (真实: 22, 预测: 25)。请计算该预测的 MAE 和 RMSE。

4.  (判断题) 只要一个预测模型的 RMSE 比另一个模型低，那么它的 MAE 也必然更低。 (对/错)

5.  (简答题) 在预测电商平台的退货率时，管理层认为“小幅低估退货率”和“小幅高估退货率”的成本是相似的，但“大幅低估退货率”（导致客服和物流准备不足）的成本是灾难性的。请问，在设计评估指标时，应该更偏向于使用 RMSE 还是 MAE，为什么？

II. 解题思路 (Solution Walkthrough)
1.  **答案: B. RMSE (均方根误差)**。
    *   **思路**: 题目核心是“避免重大预测失误”。RMSE 使用的是平方损失，它会不成比例地放大较大误差的权重。因此，一个有极端错误的模型（如模型A）会在 RMSE 上得到非常高的分（差评），而一个误差更平稳的模型（如模型B）RMSE 会相对较低。使用 RMSE 作为标准，自然会筛选掉有极端风险的模型。MAE 对所有误差线性惩罚，无法有效突出极端错误的影响。

2.  **答案: C. 数据中存在一些导致巨大误差的离群值 (outliers)**。
    *   **思路**: RMSE 对误差进行平方，MAE 则是取绝对值。如果误差分布比较均匀，两者差异不会太大。但只要出现一两个数值很大的误差，`e²` 会比 `|e|` 大得多，从而显著拉高 RMSE 的值，使其远大于 MAE。这正是存在离群值的典型信号。

3.  **答案**:
    *   **误差序列**: `(25-27)=-2`, `(28-28)=0`, `(30-26)=4`, `(22-25)=-3`
    *   **MAE 计算**:
        `MAE = (|(-2)| + |0| + |4| + |(-3)|) / 4 = (2 + 0 + 4 + 3) / 4 = 9 / 4 = 2.25`
    *   **RMSE 计算**:
        `RMSE = sqrt( ((-2)² + 0² + 4² + (-3)²) / 4 ) = sqrt( (4 + 0 + 16 + 9) / 4 ) = sqrt(29 / 4) = sqrt(7.25) ≈ 2.69`

4.  **答案: 错**。
    *   **思路**: 这是一个常见的误解。虽然 RMSE 和 MAE 都是衡量误差的指标，但它们衡量的“角度”不同。一个模型的 RMSE 较低，说明它没有太多离谱的大误差。但它可能有很多微小的误差，导致其 MAE（所有误差的平均值）反而可能高于另一个只有少数大误差但其他时候都非常精准的模型。

5.  **答案**: 应该更偏向于使用 **RMSE**。
    *   **思路**: 题目的关键在于管理层对不同大小的误差有不同的“容忍度”。他们尤其厌恶“大幅低估”这种极端情况。RMSE 的平方惩罚机制恰好能反映这种风险偏好。一个模型如果产生了“大幅低估”的错误，其 RMSE 会急剧上升，从而在评估中被判定为劣质模型。这与管理层的目标完全一致。

---
## 3. 匹配原则：评估标准如何决定最优预测 (The Matching Principle)

我们已经有了评估工具（损失函数），那么回到最初的问题：对于一个不确定的结果 `Y`，到底应该预测它的期望值、中位数还是其他什么值？答案是：**这取决于你选择用哪个工具来评估。**

### 3.1. 均方根误差 (RMSE) -> 期望值 (Expected Value)

*   **核心理论**: 如果你选择使用 **平方损失** (Quadratic Loss) 作为你的评估标准，并且你的目标是让长期来看总损失（或RMSE）最小化，那么你的最优单点预测 (optimal point forecast) 应该是该随机变量的 **期望值（均值） E(Y)**。
*   **直观解释**: 期望值是数据的“重心”。任何偏离重心的预测，都会在平方的作用下，导致更大的总体误差。数学上可以证明（如幻灯片18页所示），能够最小化 `E[(Y-z)²]` 的 `z` 值正是 `E(Y)`。
*   **模拟验证**: 幻灯片中的模拟实验（11-13页）清晰地展示了这一点。当从指数分布中抽取大量样本（S=1000）时：
    *   使用**期望值 (2)** 作为预测，得到的 RMSE 约为 `1.907`。
    *   使用**中位数 (1.386)** 作为预测，得到的 RMSE 约为 `2.004`。
    *   显然，当评估标准是 RMSE 时，使用期望值作为预测的结果更好（RMSE更低）。

### 3.2. 平均绝对误差 (MAE) -> 中位数 (Median)

*   **核心理论**: 如果你选择使用 **绝对损失** (Absolute Loss) 作为你的评估标准，并且你的目标是让长期来看总损失（或MAE）最小化，那么你的最优单点预测应该是该随机变量的 **中位数**。
*   **直观解释**: 中位数是将数据分成数量相等的两半的点。选择中位数作为预测点，可以保证高估和低估的误差总和达到一个平衡点，从而使总的绝对误差最小。任何偏离中位数的预测，都会不成比例地增加某一侧的绝对误差总和。
*   **模拟验证**: 幻灯片中的模拟实验（15-16页）也验证了这一点。当从同一分布中抽取大量样本（S=1000）时：
    *   使用**期望值 (2)** 作为预测，得到的 MAE 约为 `1.449`。
    *   使用**中位数 (1.386)** 作为预测，得到的 MAE 约为 `1.384`。
    *   当评估标准是 MAE 时，使用中位数作为预测的结果更好（MAE更低）。

### 3.3. 一致性与可引出性 (Consistency and Elicitability)

这两个是更专业的术语，用来形式化地描述“评估工具”和“预测目标”之间的匹配关系。

*   **一致性 (Consistency)**:
    *   **概念**: 如果一个损失函数 `L`，对于某个统计量 `g` (例如期望值) 来说，其期望损失 `E[L(Y, g)]` 是所有可能预测中最小的，那么我们就说这个损失函数 `L` 对于 `g` 是**一致的**。
    *   **人话版**: 如果你用了某个损失函数，它总是“鼓励”你报告真实的 `g` 值，那它就是一致的。例如，平方损失对于期望值是一致的，绝对损失对于中位数是一致的。

*   **可引出性 (Elicitability)**:
    *   **概念**: 这是一个反向的概念。如果对于某个统计量 `g`，我们**能找到**一个与之匹配的、严格一致的损失函数 `L`，那么我们就说这个统计量 `g` 是**可引出的**。
    *   **人话版**: 像期望值和中位数这样的统计量，我们能找到对应的评估工具（损失函数）来“引出”它们作为最优预测，所以它们是可引出的。但有些统计量，比如方差，就不是那么容易直接引出。

**核心启示 (Takeaway Message):** 做预测时，必须先问自己：“我的评估标准是什么？我更在乎大误差还是小误差的累积？” 然后根据这个标准，选择对应的预测目标（期望值、中位数等）。**损失函数和预测目标必须“匹配”**，否则评估就会产生误导。

---

## 4. 评估时间序列预测 (Evaluating Time Series Forecasts)

前面的例子（指数分布游戏）是理想化的，因为我们预先知道了数据的真实分布 `F`。但在真实世界中，尤其是在金融和商业领域，我们永远不知道驱动数据的真实过程 (Data Generating Process, DGP)。我们只能基于历史数据构建模型，并对未来进行预测。

这时，评估就从“理论上的最优”转向了“实践中的优劣对比”。

### 4.1. 核心术语 (Key Terminology)

在讨论时间序列预测时，有几个概念至关重要：

*   **预测原点 (Forecast Origin)**: 你进行预测的时间点。这个点是你拥有的最新信息截止的位置。例如，在 2 月 18 日股市收盘后，你的预测原点就是 2 月 18 日，你拥有截至这一天的所有数据。
*   **预测期 (Forecast Horizon, h)**: 你想要预测未来多远的时期。
    *   `h=1`: 预测紧邻的下一个时间点。例如，在 2 月 18 日预测 2 月 19 日的回报，这是一个 **单步向前预测 (one-step ahead forecast)**。
    *   `h=3`: 预测未来第三个时间点。例如，在 2 月 18 日预测 2 月 21 日的回报（假设周末休市），这是一个 **三步向前预测 (three-step ahead forecast)**。

### 4.2. 两种基础预测“模型” (Two Basic Forecasting 'Models')

为了进行对比，课程引入了两个非常简单的预测“模型”来预测股票的日回报率：

*   **模型 A (Naïve Forecast)**: 预测未来 `h` 天的回报就是**今天**的回报。
    *   **公式**: `ŷ_{t+h} = y_t`
    *   **隐含假设**: 这个模型假设时间序列是“随机游走”(Random Walk) 的，即未来的最佳预测就是当前的值，序列没有可预测的模式，变化是随机的。

*   **模型 B (Mean Forecast)**: 预测未来 `h` 天的回报是截至今天为止**所有历史回报的平均值**。
    *   **公式**: `ŷ_{t+h} = \frac{1}{t} \sum_{s=1}^{t} y_s`
    *   **隐含假设**: 这个模型假设序列是“平稳的”(Stationary)，即序列的均值在长期内是恒定的。它认为过去的平均水平是未来的最佳指引。

我们的任务是，使用真实的 Commonwealth Bank (CBA) 股票回报数据，来判断哪个模型更好。

### 4.3. 时间序列的交叉验证：扩展窗口法 (Time Series Cross-Validation: Expanding Window)

对于非时间序列数据，我们常用交叉验证 (Cross-Validation)，即把数据随机分成训练集 (Training Set) 和测试集 (Test/Validation Set)。

**但是，这在时间序列数据中是绝对错误的！**

因为时间序列数据具有时间依赖性，过去的数据会影响未来。我们不能用未来的数据去“训练”一个预测过去事件的模型，这会引入严重的 **前视偏差 (Look-ahead Bias)**。

因此，我们需要一种特殊的验证方法来模拟真实的预测过程。

*   **知识点：扩展窗口法 (Expanding Window Method)**
    *   **概念阐释**: 这是一种模拟真实预测流程的方法。我们从一个初始的训练数据窗口开始，做出一个预测，然后将真实发生的数据点纳入训练集，扩大窗口，再做下一个预测，如此循环。
    *   **举个例子 (以CBA数据为例)**:
        假设我们有从1月1日到7月15日的数据。我们决定用最后100天（比如从2月19日到7月15日）作为 **验证集 (Validation Set)**，来评估我们的模型。
        1.  **第一次预测 (Window 1)**:
            *   **训练集**: 使用从1月1日到 **2月18日** 的所有数据。
            *   **预测**: 基于这个训练集，预测 **2月19日** 的回报（单步向前，h=1）。
        2.  **第二次预测 (Window 2)**:
            *   **训练集**: 窗口扩大，使用从1月1日到 **2月19日** 的所有数据。
            *   **预测**: 基于这个更大的训练集，预测 **2月20日** 的回报。
        3.  **第三次预测 (Window 3)**:
            *   **训练集**: 窗口再次扩大，使用从1月1日到 **2月20日** 的所有数据。
            *   **预测**: 预测 **2月21日** 的回报。
        4.  **... 以此类推**，直到我们完成对验证集中所有100个数据点的预测。

*   **图示理解**:
    
    上图中，蓝色部分代表不断增长的训练数据，橙色点代表我们正在预测的下一个数据点。

*   **重要原则**:
    1.  **不作弊**: 在预测 `t+1` 时点时，你最多只能使用截至 `t` 时点的数据。例如，模型 B 在预测 2 月 19 日的回报时，只能计算截至 2 月 18 日的历史均值，而不能使用整个数据集的均值。
    2.  **不浪费数据**: 在做下一次预测（比如预测 2 月 20 日）时，应该把 2 月 19 日的真实数据也纳入模型 B 的均值计算中，而不是一直只用截至 2 月 18 日的数据。这保证了模型始终使用所有可用的历史信息。

通过这个过程，我们为模型 A 和模型 B 都生成了100个预测值。现在，我们就可以用 RMSE 或 MAE 来计算它们的总体误差，并进行比较了。

### 4.4. 结果分析

课程中的 Python 代码（幻灯片 33-36 页）执行了这个扩展窗口的流程，并计算了两个模型的 RMSE：
*   **RMSE (模型 A)**: `0.0205`
*   **RMSE (模型 B)**: `0.0144`

**结论**: 当以 RMSE 为评估标准时，模型 B（历史均值预测）的表现优于模型 A（朴素预测）。这说明，对于 CBA 的股票回报数据，使用历史均值比使用昨天的值能做出更准确的预测。

但这引出了一个新问题：模型 B 的胜出是由于其真实的优越性，还是仅仅因为 **运气好 (luck)**？我们需要一种统计方法来检验这种差异是否 **显著 (significant)**。

### 4.5. 原创例题

I. 原创例题 (Original Example Question)
1. (选择题) 一位分析师想要预测“蜜雪东城”未来一年的月度销售额。他使用了截至2024年底的所有历史数据，计算出一个总体的月均销售额，并用这个固定的平均值作为2025年每一个月的预测值。这种做法违反了时间序列验证的哪个核心原则？
   A. 浪费数据 (Wasting data)
   B. 前视偏差 (Look-ahead bias)
   C. 两者都违反了
   D. 两者都未违反

2. (选择题) 在使用扩展窗口法进行为期30天的销售预测评估时，以下哪项描述是**错误**的？
   A. 第一次预测使用的训练集是最小的。
   B. 最后一次（第30次）预测使用的训练集是最大的。
   C. 每一次预测的预测期 (forecast horizon) 都是 h=1。
   D. 为了计算模型参数，每一次都使用完全相同的数据集。

3. (判断题) 只要数据量足够大，扩展窗口法 (Expanding Window) 总是比另一种叫做“滚动窗口法 (Rolling Window)”的方法更优，因为它利用了更多的信息。(对/错)

4. (简答题) 假设你正在使用扩展窗口法评估一个预测模型。在第10次预测循环中，你的训练数据包含了时间点 1 到 100 的数据。请问，这次循环的目标是预测哪个时间点的数据？在进行第11次预测循环时，你的训练数据将包含哪些时间点的数据？

5. (简答题) 为什么说在时间序列预测中，将数据集随机打乱并进行标准的K-折交叉验证 (K-fold cross-validation) 是一个严重的方法论错误？

II. 解题思路 (Solution Walkthrough)
1.  **答案: B. 前视偏差 (Look-ahead bias)**。
    *   **思路**: 该分析师在预测2025年1月的销售额时，使用了包含2025年2月至12月数据的总体平均值。这意味着他使用了未来的信息来预测过去（相对未来而言的过去），这是典型的前视偏差。他应该在预测1月时，只用截至2024年底的数据；预测2月时，用截至2025年1月底的数据，以此类推。

2.  **答案: D. 为了计算模型参数，每一次都使用完全相同的数据集。**
    *   **思路**: D 选项是扩展窗口法的反义词。扩展窗口法的核心就在于，每一次预测后，训练数据集都会“扩展”，即加入新的观测值。因此，每一次使用的都是一个比上一次更大的、不同的数据集。A、B、C 都是对扩展窗口法（单步预测情景）的正确描述。

3.  **答案: 错**。
    *   **思路**: 这不是绝对的。扩展窗口法假设数据的底层规律是稳定的，因此越多的历史数据越好。而滚动窗口法（保持训练窗口大小不变，随时间向前滑动）则更适用于那些底层规律可能随时间变化的序列（例如，由于市场结构变化，20年前的金融数据对今天的指导意义不大）。在这种情况下，丢弃过时的数据（滚动窗口）可能比全部保留（扩展窗口）效果更好。

4.  **答案**:
    *   这次循环的目标是预测时间点 **101** 的数据（单步向前预测）。
    *   在进行第11次预测循环时，训练数据将包含时间点 **1 到 101** 的数据。

5.  **答案**: 因为随机打乱会彻底破坏数据的 **时间依赖结构 (temporal dependence)**。时间序列数据中，一个观测值的出现顺序和它与前后观测值的关系是其信息的关键部分。例如，今天的股价依赖于昨天的股价。一旦随机打乱，这种关系就消失了，模型就会在错误的数据结构上进行学习和验证，其评估结果对于真实的、按时间顺序发生的预测任务将毫无意义。

---
## 5. 检验预测的显著性 (Testing Forecast Accuracy Significance)

我们已经知道模型 B 的 RMSE 更低，但这种优势是否具有统计显著性？我们需要回答两个层面的问题：
1.  **绝对表现**: 这个预测模型本身好不好？是否存在系统性偏差？
2.  **相对表现**: 在两个模型中，一个是否**显著地**优于另一个？

### 5.1. 绝对表现检验：Mincer-Zarnowitz 回归

*   **知识点：Mincer-Zarnowitz (MZ) 回归**
    *   **概念阐释**: 这是一种通过线性回归来评估预测是否存在系统性偏差的方法。它将真实的观测值 `y_t` 对预测值 `ŷ_t` 和一个常数项进行回归。
    *   **回归方程**:
        `y_t = α + β * ŷ_t + u_t`
    *   **理想情况**: 如果一个预测是“好”的（即无偏的），那么我们期望：
        *   截距项 `α = 0`: 这意味着预测没有系统性的高估或低估。如果 `α > 0`，则预测值系统性地偏低；如果 `α < 0`，则预测值系统性地偏高。
        *   斜率项 `β = 1`: 这意味着预测值的变动能以一比一的比例解释真实值的变动。如果 `β > 1`，则模型在真实值较高时倾向于低估，在真实值较低时倾向于高估（反应不足）；如果 `β < 1`，则模型反应过度。
    *   **联合检验**: 在实践中，我们使用 **F-检验 (F-test)** 来联合检验原假设 `H₀: α = 0` 和 `β = 1`。如果 F-检验的 p-value 很小（例如小于 0.05），我们就可以拒绝原假设，认为该预测存在显著的系统性偏差。
    *   **R² 的作用**: 该回归的 R-squared 值也很有用，它表示预测值能够解释真实值变异的百分比，可以作为预测信息含量的一个度量。

*   **应用与问题**:
    *   课程对模型 A 进行了 MZ 回归（幻灯片 44-45 页），F-检验的 p-value 极小 (9.6e-16)，强烈拒绝了 `α=0, β=1` 的原假设，说明模型 A 是一个有偏的、不好的预测。
    *   然而，对模型 B 进行 MZ 回归时（幻灯片 46 页），出现了问题：系数 `β` 变得非常巨大且不稳定，并且有“多重共线性”的警告。
    *   **原因**: 模型 B 的预测值（历史均值）在一个扩展窗口中变化非常缓慢，几乎是一个常数。在回归 `y_t = α + β * ŷ_t` 中，如果 `ŷ_t` 几乎不变，它就和截距项 `α` （本身就是一个常数）产生了严重的 **多重共线性 (multicollinearity)**。因此，MZ 回归不适用于评估那些变化极小或恒定的预测序列。

### 5.2. 相对表现检验：Diebold-Mariano 检验

*   **知识点：Diebold-Mariano (DM) 检验**
    *   **概念阐释**: 当我们需要直接比较两个预测模型（A 和 B）的优劣时，DM 检验是标准工具。它专门用来检验两个模型的预测精度是否存在显著差异。
    *   **核心思想**:
        1.  **定义损失差异 (Loss Differential)**: 对于每一个时间点 `t`，我们计算两个模型损失的差异 `d_t`。
            `d_t = L(y_t, ŷ_t^(A)) - L(y_t, ŷ_t^(B))`
            这里，`L` 可以是平方损失 `(y-ŷ)²` 或绝对损失 `|y-ŷ|`。
        2.  **检验目标**: 我们想要检验的是，这个损失差异序列 `d_t` 的长期均值 `E(D)` 是否显著不为零。
    *   **原假设与备择假设**:
        *   **原假设 (Null Hypothesis), H₀**: `E(D) = 0`。即两个模型的预测精度没有显著差异。
        *   **备择假设 (Alternative Hypothesis), Hₐ**:
            *   `E(D) ≠ 0` (双边检验): 模型 A 和 B 的精度有显著差异（一个比另一个好）。
            *   `E(D) > 0` (单边检验): 模型 A 的损失显著大于模型 B，即 **模型 B 显著优于模型 A**。
            *   `E(D) < 0` (单边检验): 模型 B 的损失显著大于模型 A，即 **模型 A 显著优于模型 B**。
    *   **检验统计量**: DM 检验会计算一个类似于 t-统计量的 DM 统计值。与标准 t-检验不同的是，它考虑到了损失差异序列 `d_t` 可能存在 **自相关 (autocorrelation)** 的情况（特别是当预测期 h > 1 时），并对此进行了修正。

*   **结果解读 (幻灯片 52-53 页)**:
    *   检验 `Hₐ: B is better than A` (即 `E(D) > 0`):
        *   DM 统计量: `-2.277`
        *   p-value: `0.0124`
        (注意：课程代码实现中，`dm_test(real, forecast_A, forecast_B)` 检验的是 `A` 是否比 `B` 好。所以要检验 `B` 比 `A` 好，需要调换 B 和 A 的位置 `dm_test(real, forecast_B, forecast_A)`，或者理解 `d_t` 定义反过来，检验 `E(D) < 0`。)
        我们直接看课程提供的第三个双边检验结果更容易理解：
    *   检验 `Hₐ: A is different from B` (即 `E(D) ≠ 0`):
        *   DM 统计量: `2.277`
        *   p-value: `0.0249`

    *   **结论**: 由于双边检验的 p-value (`0.0249`) 小于常用的显著性水平 0.05，我们 **拒绝原假设**。这表明，模型 A 和模型 B 的预测精度确实存在统计上的显著差异。再结合之前 RMSE 的计算结果（模型 B 的 RMSE 更低），我们可以充满信心地得出结论：**模型 B 的预测性能显著地优于模型 A**。

### 5.3. 原创例题

I. 原创例题 (Original Example Question)
1.  (选择题) 对一个天气预报模型进行 Mincer-Zarnowitz 回归，得到 `y_t = 0.5 + 0.8 * ŷ_t`，其中 `y_t` 是真实气温，`ŷ_t` 是预测气温。这个结果最可能表明什么？
    A. 预测是完美的
    B. 预测整体上系统性偏低，且对气温变化的反应不足
    C. 预测整体上系统性偏高，且对气温变化的反应过度
    D. 预测没有系统性偏差，但反应不足

2.  (选择题) 在使用 Diebold-Mariano 检验比较模型 A 和 B 时，如果损失差异 `d_t` 定义为 `(Loss_A - Loss_B)`，并且检验 `H₀: E(D) = 0` 对 `Hₐ: E(D) > 0` 得到的 p-value 为 0.02，这意味着什么？
    A. 我们有强有力的证据表明模型 A 显著优于模型 B
    B. 我们有强有力的证据表明模型 B 显著优于模型 A
    C. 两个模型没有显著差异
    D. 检验结果无效

3.  (判断题) 只要两个预测模型的 RMSE 完全相同，那么它们的 Diebold-Mariano 检验的 p-value 一定会大于 0.05。(对/错)

4.  (简答题) 一个研究员使用 Diebold-Mariano 检验比较了两个预测美国季度 GDP 增长率的模型，并报告了双边检验的 p-value 为 0.25。他是否可以声称他的新模型（模型A）比旧模型（模型B）更好？为什么？

5.  (简答题) 解释为什么在对一个总是预测为常数的模型（例如，预测未来每天的销售额都是历史总平均值）进行 Mincer-Zarnowitz 回归时，可能会遇到问题。

II. 解题思路 (Solution Walkthrough)
1.  **答案: B. 预测整体上系统性偏低，且对气温变化的反应不足**。
    *   **思路**: 截距项 `α = 0.5 > 0`，表明真实值 `y_t` 平均比预测值 `ŷ_t` 高 0.5，即预测系统性偏低。斜率项 `β = 0.8 < 1`，表明当预测值 `ŷ_t` 增加 1 度时，真实值 `y_t` 平均只增加 0.8 度，这说明模型对变化的反应不足（under-reaction）。

2.  **答案: B. 我们有强有力的证据表明模型 B 显著优于模型 A**。
    *   **思路**: p-value 为 0.02 < 0.05，因此我们拒绝原假设 `H₀`，接受备择假设 `Hₐ: E(D) > 0`。`E(D) > 0` 意味着 `E(Loss_A - Loss_B) > 0`，即 `E(Loss_A) > E(Loss_B)`。模型A的平均损失显著大于模型B的平均损失，因此模型 B 显著更优。

3.  **答案: 错**。
    *   **思路**: RMSE 是整个验证期内误差的总体平均度量。两个模型可以有相同的总体 RMSE，但其在**每个时间点**的损失 `L(y_t, ŷ_t)` 可能是非常不同的。DM 检验关注的是损失**差异**序列 `d_t` 的行为。如果模型 A 在上半段表现好，模型 B 在下半段表现好，虽然总体 RMSE 可能一样，但 `d_t` 序列会有很强的模式，DM 检验仍然可能拒绝“无差异”的原假设。

4.  **答案**: 他**不可以**这样声称。
    *   **思路**: p-value 为 0.25，远大于 0.05。这意味着我们**不能拒绝**原假设 `H₀`，即我们没有足够的统计证据来表明两个模型的预测精度有任何显著差异。尽管模型 A 的样本内 RMSE 可能略低，但这种差异很可能仅仅是由抽样随机性造成的。

5.  **答案**: 因为这会导致严重的**多重共线性 (multicollinearity)**。Mincer-Zarnowitz 回归方程是 `y_t = α + β * ŷ_t + u_t`。如果预测值 `ŷ_t` 是一个常数（比如 `c`），那么这个方程就变成了 `y_t = α + β*c + u_t`。在这里，截距项 `α` 和 `β*c` 都是常数，模型无法区分它们。这就像试图用两个几乎完全相同的变量去解释 `y_t`，导致回归系数 `α` 和 `β` 的估计变得极不稳定且不可靠。

---
## 6. 其他重要考虑 (Other Considerations)

### 6.1. 多步向前预测 (Multistep Ahead Forecasting)

*   **挑战**: 预测期 `h` 越大，不确定性通常也越大，预测更具挑战性。
*   **模型表现**: 一个在单步预测 (`h=1`) 中表现优异的模型，在多步预测 (`h=12`) 中可能表现很差，反之亦然。
*   **实践**: 应当对不同的预测期 `h` 分别进行评估和报告结果。

### 6.2. 滚动窗口法 (Rolling Window)

*   **概念**: 与训练数据不断增大的“扩展窗口”不同，“滚动窗口”保持训练集的样本大小固定。在每一步预测后，窗口向前“滚动”一步，即加入最新的数据点，同时丢弃最老的数据点。
*   **适用场景**:
    1.  当模型的底层关系可能随时间发生变化（**模型不稳定**）时，使用滚动窗口更有意义，因为它更注重近期的数据。
    2.  当模型估计非常耗时（**计算成本高**）时，保持固定的、较小的样本量可以节省计算资源。
    这两种情况在金融数据分析中都很常见。

### 6.3. 总结

本周我们系统地学习了如何科学地评估一个预测的好坏。核心要点是：

1.  **先定标准，再谈优劣**: 必须首先明确你的 **损失函数** (Loss Function)，是更怕大错（平方损失/RMSE）还是更在乎平均误差（绝对损失/MAE）。
2.  **标准决定目标**: 你的损失函数决定了你的最优预测目标。RMSE 对应 **期望值**，MAE 对应 **中位数**。
3.  **模拟真实场景**: 评估时间序列预测必须使用 **扩展窗口** 或 **滚动窗口** 等方法，严防前视偏差。
4.  **追求统计显著性**: 不要仅凭 RMSE 或 MAE 的微小差异下结论。使用 **Mincer-Zarnowitz 回归** 评估模型的绝对偏差，并使用 **Diebold-Mariano 检验** 比较不同模型间的相对表现是否具有统计显著性。

这些原则和工具是所有复杂预测模型评估的基础。

---

# 备考复习 (Tutorial) - Week 2

## 1. 数据准备与探索 (Data Preparation and Exploration)

在对任何金融时间序列进行分析之前，首要任务是获取、清洗并理解数据。本教程以澳大利亚电信公司 Telstra (TLS.AX) 的股票数据为例，展示了从数据导入到初步探索的全过程。

### 1.1. 获取与加载数据 (Acquiring and Loading Data)

*   **知识点：从财经数据源获取数据 (Fetching Data from Financial Sources)**
    *   **概念阐释**: 现实世界中的金融分析通常始于从可靠的数据提供商处下载数据。`yfinance` 是一个流行的 Python 库，它允许用户直接从雅虎财经 (Yahoo Finance) 下载公开的股票历史数据。
    *   **核心步骤**:
        1.  指定 **股票代码 (Ticker Symbol)**，例如 `'TLS.AX'` 代表在澳大利亚证券交易所 (ASX) 上市的 Telstra。
        2.  定义 **时间范围 (Date Range)**，包括开始日期和结束日期。
        3.  使用 `yf.download()` 函数下载数据，并可以将其保存为 `.csv` 文件以供未来使用。

*   **知识点：使用 Pandas 加载与处理数据 (Loading and Processing Data with Pandas)**
    *   **概念阐释**: Pandas 是 Python 中进行数据分析的核心库。`DataFrame` 是其主要的数据结构，可以理解为一个二维表格，类似于 Excel 表格。`read_csv()` 函数用于从 CSV 文件中读取数据并创建一个 DataFrame。
    *   **时间戳数据处理**: 金融数据是典型的 **时间戳数据 (time-stamped data)**。在 Pandas 中，将日期列转换为专门的 `datetime` 类型，并将其设置为 DataFrame 的 **索引 (Index)**，是至关重要的一步。这不仅能提高数据处理效率，还能方便地按时间进行切片和筛选。
        ```python
        # 将 'Date' 列转换为 datetime 对象
        data['Date'] = pd.to_datetime(data['Date'])
        # 将 'Date' 列设为索引
        data.set_index('Date', inplace=True)
        ```

### 1.2. 初步探索 DataFrame (Initial DataFrame Exploration)

加载数据后，我们需要快速了解其基本情况。

*   **`type(data)`**: 返回数据对象的类型。对于用 Pandas 加载的数据，这通常是 `<class 'pandas.core.frame.DataFrame'>`。
*   **`len(data)`**: 返回 DataFrame 的行数，即观测值的数量。
*   **`data.shape`**: 返回一个元组 `(行数, 列数)`，提供了 DataFrame 维度的完整信息。
*   **`data.info()`**: 提供一个全面的摘要，包括索引类型、列名、每列的非空值数量以及数据类型 (Dtype)。这是检查数据是否存在缺失值和确认数据格式是否正确的首选方法。
*   **`data.head()` / `data.tail()`**: 分别显示数据的前几行和后几行，便于直观地查看数据内容。

### 1.3. 按时间筛选数据 (Slicing Data by Time)

将日期设置为索引后，Pandas 提供了非常便捷的方式来选取特定时间段的数据。

*   **举个例子**:
    *   选取 2017 年 8 月的所有数据：`data.loc['Aug-2017']` 或 `data.loc['2017-08']`。
    *   选取从 2017 年 8 月到 2019 年 8 月的所有数据：`data.loc['Aug2017':'Aug2019']`。

### 1.4. 原创例题

I. 原创例题 (Original Example Question)
1.  (选择题) 一位分析师下载了某公司2010年至2020年的日度股票数据。他运行 `data.info()` 后发现，总共有2517个条目 (entries)，但其中'Close'列的非空值 (Non-Null Count) 只有2500个。这最可能意味着什么？
    A. 数据下载有误，应该重新下载。
    B. 数据集中存在17天的缺失收盘价。
    C. `data.info()` 命令执行错误。
    D. 数据中有17天的交易量为零。

2.  (选择题) 在一个将日期设为索引的 Pandas DataFrame `df` 中，以下哪个命令**不能**正确地选取出2022年全年的数据？
    A. `df.loc['2022']`
    B. `df.loc['2022-01-01':'2022-12-31']`
    C. `df['2022']`
    D. `df.iloc[2022]`

3.  (代码填空) 请补充以下代码，使其能够从名为 `stock_data` 的 DataFrame 中选取 'Open' 和 'Close' 两列，并只保留 2021 年第三季度（7月至9月）的数据。
    ```python
    start_date = "_______"
    end_date = "_______"
    selected_data = stock_data.loc[start_date:end_date, [______, ______]]
    ```

4.  (判断题) 在 Python 中，`len(data)` 和 `data.shape[0]` 对于同一个 Pandas DataFrame `data` 总是返回相同的值。(对/错)

5.  (简答题) 为什么在处理金融时间序列数据时，通常建议将日期列转换为 `datetime` 类型并设为索引，而不是将其作为普通的数据列处理？请至少说出两点好处。

II. 解题思路 (Solution Walkthrough)
1.  **答案: B. 数据集中存在17天的缺失收盘价。**
    *   **思路**: `data.info()` 显示了每列的非空值数量。如果总条目数（即总行数）大于某一列的非空值数，就说明该列存在缺失值（NaN）。

2.  **答案: D. `df.iloc[2022]`**
    *   **思路**: `.loc[]` 是基于标签（label-based）的索引，所以可以用年份字符串 `'2022'` 来筛选。`.iloc[]` 是基于整数位置（integer-location based）的索引，`df.iloc[2022]` 会选取第2023行（因为索引从0开始），而不是选取2022年的所有数据。

3.  **答案**:
    ```python
    start_date = "2021-07-01"
    end_date = "2021-09-30"
    selected_data = stock_data.loc[start_date:end_date, ['Open', 'Close']]
    ```

4.  **答案: 对**。
    *   **思路**: `len(data)` 直接返回 DataFrame 的行数。`data.shape` 返回一个 `(行数, 列数)` 的元组，`data.shape[0]` 取的是第一个元素，即行数。两者是等价的。

5.  **答案**:
    *   **1. 便捷高效的时间筛选**: 将日期设为索引后，可以非常方便地使用 `.loc` 按年份、月份、日期范围等进行数据切片，语法简洁且执行效率高。
    *   **2. 自动对齐与绘图支持**: 当合并或计算多个时间序列时，Pandas 会根据日期索引自动对齐数据，避免错位。此外，`matplotlib` 等绘图库能自动识别 `datetime` 索引，并在绘图时正确地格式化时间轴。

---
## 2. 价格序列与回报序列 (Price Series vs. Return Series)

金融分析的核心往往不是资产的 **价格 (Price)** 本身，而是其 **回报率 (Return)**。价格序列通常是非平稳的，而回报序列则往往表现出更稳定的统计特性，便于建模。

### 2.1. 价格序列的可视化与特性 (Visualizing and Characterizing Price Series)

*   **知识点：价格时间序列图 (Time Series Plot of Prices)**
    *   **概念阐释**: 将股票价格（如收盘价 'Close'）随时间的变化绘制成图，是分析其长期趋势和行为的第一步。
    *   **TLS 价格序列特性**: 从教程中的图表可以看出，TLS 的价格序列在过去二十多年里经历了剧烈波动。它没有一个稳定的均值，表现出明显的上升和下降趋势。这种特性被称为 **非平稳性 (Non-stationarity)**。非平稳的序列很难直接预测，因为它的统计特性（如均值、方差）随时间而变。

### 2.2. 对数回报率 (Log Returns)

*   **知识点：百分比对数回报率的计算 (Calculating Percentage Log Returns)**
    *   **概念阐释**: 对数回报率是金融建模中最常用的回报率形式。它具有良好的数学特性（如时间可加性）。
    *   **公式呈现**:
        `r_t = \left( \log\left(\frac{P_t}{P_{t-1}}\right) \right) \times 100 = (\log(P_t) - \log(P_{t-1})) \times 100`
        其中 `P_t` 是在时间 `t` 的价格，`P_{t-1}` 是前一期的价格。
    *   **在 Pandas 中的实现**:
        ```python
        # p 是收盘价序列 (pd.Series)
        r = np.log(p).diff() * 100
        ```
        *   `np.log(p)`: 对价格序列中的每个元素取自然对数。
        *   `.diff()`: 计算序列中相邻元素的差值，即 `log(P_t) - log(P_{t-1})`。
        *   `* 100`: 将结果转换为百分比形式。
        *   **注意**: 第一次计算会产生一个 `NaN` (Not a Number)，因为它没有前一期的数据。在分析前需要将其移除。`r = r[1:]`。

### 2.3. 回报序列的统计特性 (Stylized Facts of Return Series)

金融资产的回报序列通常表现出一些普遍存在的统计特征，被称为 **“典型化事实” (Stylized Facts)**。

*   **知识点：描述性统计 (Descriptive Statistics)**
    *   `r.describe()`: 提供了回报序列的核心统计数据：
        *   **均值 (mean)**: TLS 回报率的均值非常接近于 0 (0.013752)，这是日度回报序列的典型特征。
        *   **标准差 (std)**: 度量了回报率的波动性。
        *   **分位数 (quantiles)**: 25%, 50% (中位数), 75% 分位数展示了数据的分布情况。

*   **知识点：偏度 (Skewness)**
    *   **概念阐释**: 衡量数据分布对称性的指标。
        *   正偏度：分布的右尾更长，意味着大的“正向意外”（大涨）比大的“负向意外”（大跌）更常见。
        *   负偏度：分布的左尾更长，意味着大的“负向意外”（大跌）比大的“正向意外”（大涨）更常见。
    *   **TLS 偏度**: `r.skew()` 结果为 `-0.39`。这是一个轻微的 **负偏度**，暗示着 TLS 股票出现极端亏损的可能性略高于出现极端盈利的可能性。

*   **知识点：峰度 (Kurtosis)**
    *   **概念阐释**: 衡量数据分布“尾部”厚度的指标。正态分布 (Gaussian Distribution) 的峰度为 3（在某些软件中，会减去3，称之为超额峰度 (Excess Kurtosis)，此时正态分布的超额峰度为 0）。
        *   高峰度（>3）: 称为 **尖峰 (Leptokurtic)** 或 **厚尾 (Fat/Heavy Tails)**。这意味着相比于正态分布，该序列出现极端值（无论正负）的概率要大得多。
    *   **TLS 峰度**: `r.kurtosis()` 结果为 `9.30`。这是一个非常高的值，远大于 3，是 **厚尾分布** 的明确证据。这意味着，像“黑天鹅”一样的极端日回报，在 TLS 股票上发生的频率远高于正态分布所预测的。

*   **知识点：波动率聚集 (Volatility Clustering)**
    *   **概念阐释**: 从回报序列的时间序列图（教程 P11）可以看出，回报率的波动性（振幅）不是恒定的。大的波动（高风险）倾向于聚集在一起，形成一个高波动时期；而小的波动（低风险）也倾向于聚集在一起，形成一个低波动时期。例如，2008年金融危机期间的波动明显大于2015年。这是金融时间序列最显著的特征之一。

**总结**: TLS 的日对数回报率序列表现出典型的金融资产特征：均值接近零、轻微负偏度、显著的厚尾现象以及波动率聚集。

### 2.4. 原创例题

I. 原创例题 (Original Example Question)
1.  (选择题) 一支股票的日回报率序列的峰度 (Kurtosis) 经计算为 1.5。这说明了什么？
    A. 该股票的回报分布是尖峰厚尾的。
    B. 该股票的回报分布是低峰薄尾的 (Platykurtic)。
    C. 该股票的回报分布比正态分布有更多的极端值。
    D. 计算有误，峰度不可能小于3。

2.  (选择题) "波动率聚集" 这一现象，意味着：
    A. 股票回报率的均值会随时间聚集变化。
    B. 股票价格总是上涨或下跌聚集在一起。
    C. 股票回报率的方差（或标准差）在不同时期是不同的，且高低波动期会持续一段时间。
    D. 股票回报率的分布是正态分布。

3.  (计算题) 假设“蜜雪东城”奶茶店连续四天的销售额分别为 ￥100, ￥105, ￥98, ￥110。请计算其百分比对数回报率（即增长率）序列。

4.  (判断题) 如果一个资产的回报率序列是正偏态 (Positively Skewed) 的，那么对于一个风险厌恶的投资者来说，这通常是一个比负偏态更受欢迎的特性。(对/错)

5.  (简答题) 为什么在金融风险管理中，认识到回报率分布的“厚尾”特性至关重要？如果错误地假设回报率为正态分布，可能会导致什么严重后果？

II. 解题思路 (Solution Walkthrough)
1.  **答案: B. 该股票的回报分布是低峰薄尾的 (Platykurtic)。**
    *   **思路**: 标准正态分布的峰度是3。小于3的峰度意味着分布比正态分布更“平坦”，尾部更“薄”，即出现极端值的概率比正态分布要低。

2.  **答案: C. 股票回报率的方差（或标准差）在不同时期是不同的，且高低波动期会持续一段时间。**
    *   **思路**: 波动率聚集的核心是“条件异方差性”，即回报率的波动性（方差）不是一个常数，而是随时间变化的，并且昨天的波动率会影响今天的波动率，从而形成“聚集”现象。

3.  **答案**:
    *   第1天 -> 第2天: `(log(105) - log(100)) * 100 ≈ (4.6539 - 4.6051) * 100 ≈ 4.88%`
    *   第2天 -> 第3天: `(log(98) - log(105)) * 100 ≈ (4.5850 - 4.6539) * 100 ≈ -6.89%`
    *   第3天 -> 第4天: `(log(110) - log(98)) * 100 ≈ (4.7005 - 4.5850) * 100 ≈ 11.55%`
    *   回报率序列为: `[NaN, 4.88%, -6.89%, 11.55%]`

4.  **答案: 对**。
    *   **思路**: 正偏态意味着右尾更长，出现巨大正回报的可能性相对较高，而巨大负回报的可能性相对较低。负偏态则相反，投资者面临着更大的“崩盘风险”。因此，在均值和方差相同的情况下，投资者通常更偏好正偏态。

5.  **答案**:
    *   **重要性**: 认识到“厚尾”意味着极端市场事件（如金融危机、股价暴跌）发生的概率远比正态分布模型预测的要高。风险管理的核心就是管理这些小概率、高影响的事件。
    *   **错误假设的后果**: 如果风险模型（如 VaR - Value at Risk）基于正态分布，它会严重**低估**发生极端亏损的可能性和亏损的幅度。这可能导致公司或投资者配置的风险准备金不足，杠杆过高，一旦“黑天鹅”事件发生，将面临破产的风险。


---

## 3. 分布拟合与模型检验 (Distribution Fitting and Model Checking)

我们已经通过描述性统计发现 TLS 回报序列存在“厚尾”现象。接下来，我们将使用更正式的可视化和统计工具来验证这一观察，并判断哪种理论分布能更好地描述数据，特别是其尾部行为。

### 3.1. 可视化检验：直方图与核密度估计

*   **知识点：直方图 (Histogram)**
    *   **概念阐释**: 直方图将数据的取值范围划分为若干个“箱子 (bins)”，然后统计落入每个箱子内的数据点的数量。它可以直观地展示数据的分布形状、中心位置和离散程度。
    *   **解读**: 教程中的直方图显示，TLS 回报率高度集中在 0 附近，形成一个尖锐的峰，并且向两侧延伸的尾部较长，初步印证了“尖峰厚尾”的特征。

*   **知识点：核密度估计图 (Kernel Density Estimate, KDE Plot)**
    *   **概念阐释**: KDE 图可以看作是直方图的平滑版本。它通过一个“核函数”来估计数据点的连续概率密度函数，从而提供一个更平滑、更精细的分布形状视图。
    *   **与正态分布对比**: 在教程中（P8-P9），我们将 TLS 回报率的 KDE 图（蓝色线）与一个具有相同均值和标准差的正态分布的概率密度函数（橙色线）绘制在了一起。
        *   **中心区域**: 蓝色线在 0 附近比橙色线更高更尖，证实了 **尖峰 (Leptokurtosis)** 的特性。
        *   **尾部区域**: 在远离中心的位置（例如 `|r| > 3`），蓝色线位于橙色线之上，这直观地展示了 **厚尾 (Fat Tails)** 的存在——即真实数据中出现极端值的概率显著高于正态分布的预测。

### 3.2. 可视化检验：QQ 图

*   **知识点：分位数-分位数图 (Quantile-Quantile Plot, QQ Plot)**
    *   **概念阐释**: QQ 图是一种强大的、用于检验样本数据是否来自于某个特定理论分布（如此处的正态分布）的可视化工具。
    *   **构建原理**:
        1.  横坐标 (Theoretical Quantiles): 理论分布（如标准正态分布）的分位数。
        2.  纵坐标 (Sample Quantiles): 样本数据的分位数。
    *   **解读**:
        *   如果样本数据**完全**来自于该理论分布，那么 QQ 图上的所有点将紧密地落在一条 **45度对角线** 上。
        *   **系统性偏离** 这条直线，则表明样本分布与理论分布存在差异。
    *   **TLS 回报率的 QQ 图分析 (教程 P10)**:
        *   **中间部分**: 在中心区域（大约 -2 到 2 之间），数据点与 45 度线拟合得相对较好。
        *   **尾部偏离**: 在两个尾端，数据点显著地偏离了直线。
            *   **左尾（负向极端值）**: 样本分位数（蓝点）位于直线的**下方**，说明实际观测到的极端负回报比正态分布预测的要“更负”（即亏损更大）。
            *   **右尾（正向极端值）**: 样本分位数（蓝点）位于直线的**上方**，说明实际观测到的极端正回报比正态分布预测的要“更正”（即盈利更高）。
        *   这种“S”形或“两端翘起”的偏离模式是 **厚尾分布** 在 QQ 图上的典型特征。

### 3.3. 尾部建模：正态分布 vs. t 分布

既然正态分布不能很好地描述尾部，我们需要寻找更合适的模型。

*   **知识点：学生 t 分布 (Student's t-distribution)**
    *   **概念阐释**: t 分布是一种形状与正态分布相似但具有更厚尾部的概率分布。它由一个关键参数——**自由度 (degrees of freedom, df)**——来控制其尾部的厚度。
    *   **自由度 (df)**:
        *   df 越小，尾部越厚，峰部越尖。
        *   当 df → ∞ 时，t 分布收敛于正态分布。
        *   在金融实践中，通常使用较小的 df (如 3 到 8) 来捕捉厚尾现象。

*   **知识点：分位数函数 (Quantile Function / Inverse CDF / PPF)**
    *   **概念阐释**: 累积分布函数 (CDF) 回答“小于x的概率是多少？”。而分位数函数 (PPF, Percent Point Function) 回答其逆问题：“概率为p时对应的x值是多少？”。例如，`stats.norm.ppf(0.001)` 会返回标准正态分布下，其左侧面积为 0.1% 的那个点的值。
    *   **应用**: 我们可以用它来计算理论上的极端亏损阈值。

*   **比较分析**: 教程中计算了样本数据、正态分布和 t 分布 (df=5) 在 0.1% 分位数上的值：
    *   **标准化后的样本数据 0.1% 分位数**: `-6.43`
    *   **标准正态分布 0.1% 分位数 (理论值)**: `-3.09`
    *   **自由度为 5 的 t 分布 0.1% 分位数 (理论值)**: `-5.89`

    **结论**: 样本的极端分位数 (`-6.43`) 远比正态分布的 (`-3.09`) 更极端，但与 t 分布的 (`-5.89`) 更为接近。这强有力地证明了 **t 分布比正态分布更适合用来建模 TLS 回报率的尾部风险**。

### 3.4. 高斯随机游走模型的适用性 (Applicability of Gaussian Random Walk Model)

*   **知识点：高斯随机游走模型 (Gaussian Random Walk, GRW)**
    *   **定义**: GRW 模型假设资产的 **对数价格 (log price)** 服从一个随机游走过程，并且其每一步的变化（即 **对数回报率**）服从一个 **正态分布 (Gaussian)**。
        `log(P_t) = log(P_{t-1}) + ε_t`,  其中 `ε_t ~ N(μ, σ²)`
    *   **适用性检验**: 基于我们上述所有的分析（KDE 图、QQ 图、分位数比较），TLS 的对数回报率**不服从**正态分布，因为它具有显著的厚尾特性。
    *   **最终结论**: 因此，我们可以断定 **高斯随机游走模型不适用于描述 TLS 的对数价格行为**。在实际建模中，需要使用能够捕捉厚尾特性的模型，例如假设回报率服从 t 分布的随机游走模型，或者更高级的 GARCH 类模型。

### 3.5. 原创例题

I. 原创例题 (Original Example Question)
1.  (选择题) 在一张正态 QQ 图上，如果数据点在图的左下角系统性地低于45度线，而在右上角系统性地高于45度线，这表明样本数据的分布是：
    A. 左偏 (Left-skewed)
    B. 右偏 (Right-skewed)
    C. 薄尾 (Thin-tailed)
    D. 厚尾 (Fat-tailed)

2.  (选择题) 一位风险分析师正在使用 t 分布为“蜜雪东城”的日销售增长率建模。他发现使用自由度 df=4 时模型拟合得很好。后来公司运营趋于稳定，极端日增长率出现的频率降低。如果此时他重新建模，最可能选择的自由度 df' 会是：
    A. df' = 2
    B. df' = 4
    C. df' = 8
    D. 无法判断

3.  (计算题) 假设某资产的日回报率服从均值为 0.05%，标准差为 2% 的正态分布。请使用分位数函数（假设 `stats.norm.ppf(0.01) ≈ -2.33`）计算其 Value-at-Risk (VaR) 在 99% 置信水平下的值。即，有 1% 的可能性，单日亏损会超过多少？

4.  (判断题) 核密度估计图 (KDE) 总是比直方图更能准确地反映数据的真实潜在分布。(对/错)

5.  (简答题) 简单解释为什么高斯随机游走模型（GRW）无法捕捉到金融市场中的“波动率聚集”现象。

II. 解题思路 (Solution Walkthrough)
1.  **答案: D. 厚尾 (Fat-tailed)**。
    *   **思路**: 这正是教程中描述的厚尾分布在 QQ 图上的典型“S”形特征。左下角低于直线意味着样本的负向极端值比正态分布的更负；右上角高于直线意味着样本的正向极端值比正态分布的更正。

2.  **答案: C. df' = 8**。
    *   **思路**: 极端值频率降低意味着分布的尾部变“薄”了，更接近正态分布。在 t 分布中，自由度 df 越大，尾部越薄。因此，他应该选择一个比 4 更大的自由度。

3.  **答案**:
    *   **VaR 定义**: 我们要找一个亏损值 `L`，使得 `P(Return < -L) = 1%`。这等价于寻找回报率分布的左侧 1% 分位数。
    *   **标准化**: `(X - μ) / σ ~ N(0, 1)`。 我们要找 `X` 使得 `P( (X - μ)/σ < (X - μ)/σ ) = 0.01`。
        所以 `(X - μ)/σ` 就是标准正态分布的 1% 分位数，即 `stats.norm.ppf(0.01) ≈ -2.33`。
    *   **计算**:
        `(X - 0.0005) / 0.02 = -2.33`
        `X = -2.33 * 0.02 + 0.0005 = -0.0466 + 0.0005 = -0.0461`
    *   **结果解读**: 1% VaR 是 `-4.61%`。即有1%的可能性，单日亏损会超过 `4.61%`。

4.  **答案: 错**。
    *   **思路**: KDE 提供了更平滑的视图，但其形状依赖于一个称为“带宽 (bandwidth)”的平滑参数的选择。不合适的带宽选择可能导致对真实分布的过度平滑或欠平滑，从而产生误导。直方图虽然粗糙，但它更直接地反映了数据的原始分组情况。两者是互补的工具，没有绝对的优劣。

5.  **答案**: 高斯随机游走模型的核心假设是，每一步的变动 `ε_t` (即回报率) 是 **独立同分布 (independent and identically distributed, i.i.d.)** 的，并且服从一个**方差恒定**的正态分布。而“波动率聚集”现象的本质是回报率的波动性（方差）是随时间变化的，并且今天的波动与昨天的波动相关。GRW 模型的恒定方差假设，使其从根本上无法描述这种时变的、自相关的波动性。

---

## B. 更多练习题 (More Practice Questions)

### 1. 原始练习题 (Source Material Questions)

1.  Analyze the provided time-series plot of a commodity's price from 2010 to 2025. Based on the visual evidence, would you classify this series as stationary? Justify your reasoning regarding its predictability over different time horizons.
2.  You are given the following descriptive statistics for the daily log returns of a tech stock: `mean = 0.02`, `std = 2.5`, `skew = -0.8`, and `kurtosis = 12`. What do these figures tell you about the return distribution, especially concerning symmetry and the likelihood of extreme events compared to a Gaussian distribution?
3.  The 0.5% quantile for a stock's daily return is calculated to be -6.5%. How would you interpret this value for a portfolio manager concerned with tail risk? On what major assumption does the reliability of this estimate depend?
4.  Examine the Kernel Density Estimate (KDE) plot for a set of returns, which is overlaid with a normal distribution curve of the same mean and variance. If the KDE plot is visibly taller and narrower at the center and fatter at the tails than the normal curve, what does this imply about the return distribution's characteristics?
5.  A Normal QQ plot for a hedge fund's monthly returns shows that the data points in the middle section align well with the 45-degree line, but the points at both the upper and lower ends deviate significantly from the line. Describe the nature of these deviations and what they signify about the fund's return distribution.
6.  Looking at a time-series plot of a stock's daily log returns from 2000 to 2020, you observe that the magnitude of fluctuations is very high during 2008-2009 and 2020, but relatively calm during 2014-2016. What is the name of this phenomenon and what does it imply about the variance of the returns?
7.  An analyst models a stock's log prices using a Gaussian Random Walk (GRW) model. After analyzing the historical returns, she finds a kurtosis of 8.5. Is her choice of the GRW model appropriate? Explain why or why not.

### 2. 原创练习题 (Original Practice Questions)

1.  Explain the purpose of the `.diff()` method in Pandas when calculating log returns from a log price series. What is the value of the first element in the resulting series and why?
2.  If a stock price goes from $120 to $115 in one day, calculate its percentage log return. Show your calculation.
3.  A return series has a skewness of +1.2. Would an investor typically be more concerned about extreme negative returns or extreme positive returns for this asset? Why?
4.  Why is it standard practice to analyze financial returns rather than raw asset prices when building statistical models? Provide at least two reasons.
5.  If you are comparing two distributions using their Kurtosis values, which one would have a higher probability of generating extreme "Black Swan" events: Distribution A with Kurtosis = 5 or Distribution B with Kurtosis = 10?
6.  What is the primary advantage of a Kernel Density Estimate (KDE) plot over a standard histogram for visualizing data distributions?
7.  In a Normal QQ plot, if all the sample quantiles lie perfectly on the 45-degree theoretical quantile line, what can you conclude about the data?
8.  The standard deviation of a stock's daily returns is often used as a proxy for what financial concept?
9.  A researcher calculates the 99.9% quantile of a standardized return series and gets a value of 4.5. He then finds that the theoretical 99.9% quantile for a standard normal distribution is approximately 3.09. What does this comparison suggest?
10. Explain the role of the "degrees of freedom" parameter in a Student's t-distribution. How does its value affect the shape of the distribution, particularly its tails?
11. If a Gaussian Random Walk model were a perfect description of a stock's log price, what would you expect the Kurtosis of its daily log returns to be?
12. Between `stats.norm.ppf(0.05)` and `stats.t.ppf(0.05, df=4)`, which would produce a larger negative number? Explain the intuition behind your answer.
13. You use the command `data.loc['2023-01']` on a Pandas DataFrame. What must be true about the DataFrame's index for this command to work correctly?
14. A daily return series has a mean of 0.01%. Is this value alone sufficient to determine if it is a good investment? What other statistic is crucial for making this assessment?
15. The phenomenon of "volatility clustering" violates a key assumption of the simple Gaussian Random Walk model. What is that assumption?

---

## C. 练习题答案 (Practice Question Answers)

### 1. 原始练习题 (Source Material Questions)

1.  **题号与核心概述**: 价格序列图的平稳性分析
    *   **答案**: 该序列很可能被归类为 **非平稳 (non-stationary)** 的。
    *   **解析**: 平稳时间序列的统计特性（如均值和方差）不随时间改变。然而，股票或商品的价格图通常显示出明显的趋势（长期上涨或下跌）和随时间变化的波动性，其均值明显不是一个常数。这种非平稳性意味着它的长期可预测性很低。虽然短期内可能存在一些动量，但长期来看，其路径类似于随机游走，难以准确预测。

2.  **题号与核心概述**: 解读回报率的描述性统计
    *   **答案**: 该分布是 **轻微负偏态** 且具有显著的 **尖峰厚尾** 特征。
    *   **解析**:
        *   **对称性**: 偏度 (skew) 为 -0.8，是一个负值，表明分布的左尾比右尾更长。这意味着相比于极端的大幅上涨，该股票出现极端的大幅下跌的可能性更高。
        *   **极端事件**: 峰度 (kurtosis) 为 12，远大于正态分布的峰度 3。这表明该回报分布是“尖峰厚尾”的，出现极端值（无论正负）的概率远高于一个相同均值和方差的正态分布所预测的。

3.  **题号与核心概述**: 解释分位数与尾部风险
    *   **答案**: 这意味着在所有交易日中，有 0.5% 的日子里，该股票的日亏损会达到或超过 6.5%。这是衡量尾部风险的一个指标。该估计的可靠性主要取决于 **样本量足够大且能够代表未来的真实分布**。
    *   **解析**: 分位数是对数据分布在特定概率点上的切割。0.5% 分位数是这样一个点，数据中有 0.5% 的观测值小于或等于它。对于风险经理来说，这定义了一个在极端市场情况下可能发生的亏损水平。如果样本量太小，或者历史数据无法代表未来的市场环境，那么这个基于历史样本计算出的分位数估计可能就不准确。

4.  **题号与核心概述**: 解读KDE与正态分布的对比图
    *   **答案**: 这意味着该回报分布具有 **尖峰 (Leptokurtic)** 和 **厚尾 (Fat-tailed)** 的特性。
    *   **解析**: KDE图在中心处更高更窄，说明更多的回报值聚集在均值附近，这导致了分布的“尖峰”。同时，在远离中心的尾部区域，KDE图高于正态分布曲线，说明实际数据中出现极端值的概率比正态分布预测的要高，这就是“厚尾”。

5.  **题号与核心概述**: 解读QQ图的尾部偏离
    *   **答案**: 在上尾部（右上角），数据点会系统性地高于45度线；在下尾部（左下角），数据点会系统性地低于45度线。这标志着该基金的回报分布是 **厚尾** 的。
    *   **解析**: QQ图比较的是样本分位数和理论分位数。尾部的偏离表明样本中的极端值比理论上的正态分布要更“极端”。例如，样本中最大的那1%的回报（上尾部），比正态分布中最大的1%的回报还要大，因此点会出现在对角线上方。反之亦然，样本中最差的1%的回报比正态分布中最差的1%回报还要差，因此点会出现在对角线下方。

6.  **题号与核心概述**: 识别波动率聚集现象
    *   **答案**: 这种现象被称为 **波动率聚集 (Volatility Clustering)**。它意味着回报的 **方差 (variance)** 是随时间变化的（时变性）。
    *   **解析**: 波动率聚集是金融时间序列的一个典型化事实，即“高波动的时期之后倾向于跟随着高波动的时期，低波动的时期之后倾向于跟随着低波动的时期”。这表明回报率的方差不是一个恒定值，而是在不同时期有高低之分，且这种状态会持续一段时间。

7.  **题号与核心概述**: 判断高斯随机游走模型的适用性
    *   **答案**: **不适用**。
    *   **解析**: 高斯随机游走 (GRW) 模型的核心假设是，对数回报率服从一个高斯分布，即正态分布。正态分布的峰度是3。而实际数据的峰度为8.5，远大于3，这表明数据具有强烈的“厚尾”特性。GRW模型会严重低估极端事件发生的概率，因此它不是一个合适的模型。

### 2. 原创练习题 (Original Practice Questions)

1.  **题号与核心概述**: Pandas `.diff()` 方法的作用
    *   **答案**: `.diff()` 方法用于计算一个序列中相邻元素的差值。在计算对数回报率 `log(Pt) - log(Pt-1)` 时，它恰好能实现这一步。结果序列的第一个元素值是 `NaN` (Not a Number)，因为第一个价格 `P₀` 没有前一个元素 `P₋₁` 与之相减。
    *   **解析**: 时间序列的差分是核心操作之一。`.diff(1)` 计算的是一阶差分，即 `x_t - x_{t-1}`。由于 `x_0` 没有 `x_{-1}`，因此第一个计算结果为空。

2.  **题号与核心概述**: 计算对数回报率
    *   **答案**: 约 -4.25%。
    *   **解析**: 公式为 `(log(P_t) - log(P_{t-1})) * 100`。代入数值：`(log(115) - log(120)) * 100 ≈ (4.7449 - 4.7875) * 100 = -0.0426 * 100 = -4.26%`。

3.  **题号与核心概述**: 解读正偏度
    *   **答案**: 投资者通常会更关注极端 **正向** 回报。
    *   **解析**: 偏度为正 (+1.2) 意味着分布的右尾更长。这表明，虽然不常见，但该资产出现极端大幅上涨的可能性要显著高于出现极端大幅下跌的可能性。对于投资者而言，这是一种有利的非对称性。

4.  **题号与核心概述**: 分析回报率而非价格的原因
    *   **答案**: 1. **平稳性 (Stationarity)**：价格序列通常是非平稳的，而回报序列通常更接近平稳，这使得统计建模更为简单和可靠。2. **无单位且可比性 (Unit-free and Comparable)**：回报率（如百分比）是没有单位的，这使得比较不同价格水平的资产（如股价为￥10的股票和股价为￥1000的股票）的投资表现成为可能。
    *   **解析**: 这两个是核心原因。平稳性是大多数经典时间序列模型的前提。可比性则是进行资产配置和绩效评估的基础。

5.  **题号与核心概述**: 峰度与黑天鹅事件
    *   **答案**: **分布B (Kurtosis = 10)**。
    *   **解析**: 峰度是衡量尾部厚度的指标。峰度值越高，尾部越厚，意味着发生远离均值的极端事件（黑天鹅）的概率越大。因为 10 > 5，所以分布B有更厚的尾部和更高的极端事件概率。

6.  **题号与核心概述**: KDE 相对于直方图的优势
    *   **答案**: KDE 提供了数据分布的 **平滑、连续** 的估计，不像直方图那样其形状会受到“箱子”数量和边界选择的强烈影响。
    *   **解析**: KDE 不受分箱效应的干扰，能够更好地揭示分布的细微形态，如多峰性。但它也有其参数（带宽）选择的问题。

7.  **题号与核心概述**: 解读完美的QQ图
    *   **答案**: 这可以得出结论：样本数据 **非常完美地** 来自于所比较的理论分布（在这里是正态分布）。
    *   **解析**: QQ图是检验分布拟合度的金标准之一。如果所有点都落在45度线上，说明在每一个分位数上，样本分布都与理论分布完全匹配。

8.  **题号与核心概述**: 标准差与金融概念
    *   **答案**: **风险 (Risk)** 或 **波动率 (Volatility)**。
    *   **解析**: 在金融领域，标准差衡量了回报率围绕其均值的离散程度。离散程度越大，未来的不确定性就越高，因此标准差被广泛用作衡量资产风险或波动性的基本指标。

9.  **题号与核心概述**: 比较样本分位数与理论分位数
    *   **答案**: 这表明样本分布的 **右尾比正态分布要厚得多**。
    *   **解析**: 99.9%分位数衡量的是分布的右侧极端值。样本的该分位数值 (4.5) 远大于正态分布的理论值 (3.09)，说明在现实中发生的极端正回报，比正态分布模型所预测的要大得多。

10. **题号与核心概述**: t分布中的自由度
    *   **答案**: 自由度 (df) 控制t分布的峰度和尾部厚度。df值 **越小**，分布的峰部越尖，**尾部越厚**。随着df值增大，t分布逐渐逼近标准正态分布。
    *   **解析**: 这使得t分布成为一个灵活的工具。对于有极端事件的金融数据，可以选择较小的df；对于接近正态的数据，可以选择较大的df。

11. **题号与核心概述**: GRW模型的理论峰度
    *   **答案**: 峰度应为 **3** (或者超额峰度为0)。
    *   **解析**: GRW模型假设对数回报率服从高斯分布，即正态分布。根据定义，标准正态分布的峰度是3。

12. **题号与核心概述**: 比较正态与t分布的分位数
    *   **答案**: `stats.t.ppf(0.05, df=4)` 会产生一个更大的负数。
    *   **解析**: t分布的尾部比正态分布更厚。这意味着，为了在左尾累积相同的概率（如此处的5%），t分布需要向左延伸到更远的位置。因此，t分布的5%分位数会比标准正态分布的5%分位数更小（即绝对值更大）。

13. **题号与核心概述**: Pandas时间索引
    *   **答案**: DataFrame的索引必须是 **`DatetimeIndex` 类型**。
    *   **解析**: 只有将索引设置为时间序列类型，Pandas才能识别并解析像 `'2023-01'` 这样的日期字符串，并执行基于时间的切片操作。

14. **题号与核心概述**: 均值与风险评估
    *   **答案**: **不充分**。必须结合 **标准差 (standard deviation)** 或其他风险度量来评估。
    *   **解析**: 投资决策是风险和回报的权衡。一个略正的平均回报如果伴随着巨大的波动性（高标准差），可能是一个非常糟糕的投资。夏普比率 (Sharpe Ratio) 等指标就是同时考虑了均值（回报）和标准差（风险）的综合评估工具。

15. **题号与核心概述**: 波动率聚集与GRW模型的假设冲突
    *   **答案**: “波动率聚集”违反了GRW模型中回报率是 **同分布 (identically distributed)** 的假设，特别是 **方差恒定 (constant variance / homoscedasticity)** 的部分。
    *   **解析**: GRW假设回报率 `ε_t` 每次都从同一个（方差为 `σ²` 的）正态分布中抽取。而波动率聚集现象表明，`ε_t` 的方差在不同时期是不同的，因此它们不是“同分布”的。

